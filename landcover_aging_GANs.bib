
@article{Achard_2004,
	file = {org_files/pdf/achard_2004.pdf},
	doi = {10.1029/2003gb002142},
	url = {https://doi.org/10.1029%2F2003gb002142},
	year = 2004,
	month = {may},
	publisher = {American Geophysical Union ({AGU})},
	volume = {18},
	number = {2},
	pages = {n/a--n/a},
	author = {Fr{\'{e}}d{\'{e}}ric Achard and Hugh D. Eva and Philippe Mayaux and Hans-Jürgen Stibig and Alan Belward},
	title = {Improved estimates of net carbon emissions from land cover change in the tropics for the 1990s},
	journal = {Global Biogeochem. Cycles}
}

@inproceedings{Alem_2020,
	file = {org_files/pdf/alem2020.pdf},
	doi = {10.1109/icrito48877.2020.9197824},
	url = {https://doi.org/10.1109%2Ficrito48877.2020.9197824},
	year = 2020,
	month = {jun},
	publisher = {{IEEE}},
	author = {Abebaw Alem and Shailender Kumar},
	title = {Deep Learning Methods for Land Cover and Land Use Classification in Remote Sensing: A Review},
	booktitle = {2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) ({ICRITO})}
}

@article{Alhassan_2019,
	file = {org_files/pdf/alhassan_2019.pdf},
	doi = {10.1007/s00521-019-04349-9},
	url = {https://doi.org/10.1007%2Fs00521-019-04349-9},
	year = 2019,
	month = {jul},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {32},
	number = {12},
	pages = {8529--8544},
	author = {Victor Alhassan and Christopher Henry and Sheela Ramanna and Christopher Storie},
	title = {A deep learning framework for land-use/land-cover mapping and analysis using multispectral satellite imagery},
	journal = {Neural Comput & Applic}
}

@article{Aspri_2020,
	file = {org_files/pdf/aspri_2020.pdf},
	abstract = {<jats:p>Deep Neural Networks (DNNs) have established themselves as a fundamental tool in numerous computational modeling applications, overcoming the challenge of defining use-case-specific feature extraction processing by incorporating this stage into unified end-to-end trainable models. Despite their capabilities in modeling, training large-scale DNN models is a very computation-intensive task that most single machines are often incapable of accomplishing. To address this issue, different parallelization schemes were proposed. Nevertheless, network overheads as well as optimal resource allocation pose as major challenges, since network communication is generally slower than intra-machine communication while some layers are more computationally expensive than others. In this work, we consider a novel multimodal DNN based on the Convolutional Neural Network architecture and explore several different ways to optimize its performance when training is executed on an Apache Spark Cluster. We evaluate the performance of different architectures via the metrics of network traffic and processing power, considering the case of land cover classification from remote sensing observations. Furthermore, we compare our architectures with an identical DNN architecture modeled after a data parallelization approach by using the metrics of classification accuracy and inference execution time. The experiments show that the way a model is parallelized has tremendous effect on resource allocation and hyperparameter tuning can reduce network overheads. Experimental results also demonstrate that proposed model parallelization schemes achieve more efficient resource use and more accurate predictions compared to data parallelization approaches.</jats:p>},
	author = {Maria Aspri and Grigorios Tsagkatakis and Panagiotis Tsakalides},
	doi = {10.3390/rs12172670},
	journal = {Remote Sensing},
	month = {aug},
	number = {17},
	pages = {2670},
	publisher = {{MDPI} {AG}},
	title = {Distributed Training and Inference of Deep Learning Models for Multi-Modal Land Cover Classification},
	url = {https://doi.org/10.3390%2Frs12172670},
	volume = {12},
	year = {2020}
}

@incollection{Aung_2018,
	doi = {10.1007/978-981-13-0869-7_11},
	url = {https://doi.org/10.1007%2F978-981-13-0869-7_11},
	year = 2018,
	month = {jun},
	publisher = {Springer Singapore},
	pages = {94--103},
	author = {Su Wit Yi Aung and Soe Soe Khaing and Shwe Thinzar Aung},
	title = {Multi-label Land Cover Indices Classification of Satellite Images Using Deep Learning},
	booktitle = {Advances in Intelligent Systems and Computing}
}

@article{Ayhan_2020,
	abstract = {<jats:p>Land cover classification with the focus on chlorophyll-rich vegetation detection plays an important role in urban growth monitoring and planning, autonomous navigation, drone mapping, biodiversity conservation, etc. Conventional approaches usually apply the normalized difference vegetation index (NDVI) for vegetation detection. In this paper, we investigate the performance of deep learning and conventional methods for vegetation detection. Two deep learning methods, DeepLabV3+ and our customized convolutional neural network (CNN) were evaluated with respect to their detection performance when training and testing datasets originated from different geographical sites with different image resolutions. A novel object-based vegetation detection approach, which utilizes NDVI, computer vision, and machine learning (ML) techniques, is also proposed. The vegetation detection methods were applied to high-resolution airborne color images which consist of RGB and near-infrared (NIR) bands. RGB color images alone were also used with the two deep learning methods to examine their detection performances without the NIR band. The detection performances of the deep learning methods with respect to the object-based detection approach are discussed and sample images from the datasets are used for demonstrations.</jats:p>},
	author = {Bulent Ayhan and Chiman Kwan and Bence Budavari and Liyun Kwan and Yan Lu and Daniel Perez and Jiang Li and Dimitrios Skarlatos and Marinos Vlachos},
	doi = {10.3390/rs12152502},
	journal = {Remote Sensing},
	month = {aug},
	number = {15},
	pages = {2502},
	publisher = {{MDPI} {AG}},
	title = {Vegetation Detection Using Deep Learning and Conventional Methods},
	url = {https://doi.org/10.3390%2Frs12152502},
	volume = {12},
	year = {2020}
}

@inproceedings{Ben_Hamida_2017,
	doi = {10.1109/igarss.2017.8127520},
	url = {https://doi.org/10.1109%2Figarss.2017.8127520},
	year = 2017,
	month = {jul},
	publisher = {{IEEE}},
	author = {A. Ben Hamida and A. Benoit and P. Lambert and L. Klein and C. Ben Amar and N. Audebert and S. Lefevre},
	title = {Deep learning for semantic segmentation of remote sensing images with rich spectral content},
	booktitle = {2017 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})}
}

@article{Benedetti_2018,
	doi = {10.1109/jstars.2018.2876357},
	url = {https://doi.org/10.1109%2Fjstars.2018.2876357},
	year = 2018,
	month = {dec},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {11},
	number = {12},
	pages = {4939--4949},
	author = {Paola Benedetti and Dino Ienco and Raffaele Gaetano and Kenji Ose and Ruggero G. Pensa and Stephane Dupuy},
	title = {{\textdollar}M{\^{}}3{\textbackslash}text$\lbrace$Fusion$\rbrace${\textdollar}: A Deep Learning Architecture for Multiscale Multimodal Multitemporal Satellite Data Fusion},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@inproceedings{Bergado_2016,
	doi = {10.1109/igarss.2016.7729387},
	url = {https://doi.org/10.1109%2Figarss.2016.7729387},
	year = 2016,
	month = {jul},
	publisher = {{IEEE}},
	author = {John Ray Bergado and Claudio Persello and Caroline Gevaert},
	title = {A deep learning approach to the classification of sub-decimetre resolution aerial images},
	booktitle = {2016 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})}
}

@article{Bhosle_2019,
	doi = {10.1007/s12524-019-01041-2},
	url = {https://doi.org/10.1007%2Fs12524-019-01041-2},
	year = 2019,
	month = {sep},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {47},
	number = {11},
	pages = {1949--1958},
	author = {Kavita Bhosle and Vijaya Musande},
	title = {Evaluation of Deep Learning {CNN} Model for Land Use Land Cover Classification and Crop Identification Using Hyperspectral Remote Sensing Images},
	journal = {J Indian Soc Remote Sens}
}

@incollection{Botella_2018,
	doi = {10.1007/978-3-319-76445-0_10},
	url = {https://doi.org/10.1007%2F978-3-319-76445-0_10},
	year = 2018,
	publisher = {Springer International Publishing},
	pages = {169--199},
	author = {Christophe Botella and Alexis Joly and Pierre Bonnet and Pascal Monestiez and Fran{\c{c}}ois Munoz},
	title = {A Deep Learning Approach to Species Distribution Modelling},
	booktitle = {Multimedia Tools and Applications for Environmental {\&} Biodiversity Informatics}
}

@inproceedings{Bupphawat_2017,
	doi = {10.1109/ecticon.2017.8096298},
	url = {https://doi.org/10.1109%2Fecticon.2017.8096298},
	year = 2017,
	month = {jun},
	publisher = {{IEEE}},
	author = {Watsana Bupphawat and Teerasit Kasetkasem and Itsuo Kumazawa and Preesan Rakwatin and Thitiporn Chanwimaluang},
	title = {Super-resolution land cover mapping based on deep learning and level set method},
	booktitle = {2017 14th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology ({ECTI}-{CON})}
}

@article{Campos_Taberner_2020,
	abstract = {<jats:title>Abstract</jats:title>
              <jats:p>The use of deep learning (DL) approaches for the analysis of remote sensing (RS) data is rapidly increasing. DL techniques have provided excellent results in applications ranging from parameter estimation to image classification and anomaly detection. Although the vast majority of studies report precision indicators, there is a lack of studies dealing with the interpretability of the predictions. This shortcoming hampers a wider adoption of DL approaches by a wider users community, as model’s decisions are not accountable. In applications that involve the management of public budgets or policy compliance, a better interpretability of predictions is strictly required. This work aims to deepen the understanding of a recurrent neural network for land use classification based on Sentinel-2 time series in the context of the European Common Agricultural Policy (CAP). This permits to address the relevance of predictors in the classification process leading to an improved understanding of the behaviour of the network. The conducted analysis demonstrates that the red and near infrared Sentinel-2 bands convey the most useful information. With respect to the temporal information, the features derived from summer acquisitions were the most influential. These results contribute to the understanding of models used for decision making in the CAP to accomplish the European Green Deal (EGD) designed in order to counteract climate change, to protect biodiversity and ecosystems, and to ensure a fair economic return for farmers.</jats:p>},
	author = {Manuel Campos-Taberner and Francisco Javier Garc{\'{\i}}a-Haro and Beatriz Mart{\'{\i}}nez and Emma Izquierdo-Verdiguier and Clement Atzberger and Gustau Camps-Valls and Mar{\'{\i}}a Amparo Gilabert},
	doi = {10.1038/s41598-020-74215-5},
	journal = {Sci Rep},
	month = {oct},
	number = {1},
	publisher = {Springer Science and Business Media {LLC}},
	title = {Understanding deep learning in land use classification based on Sentinel-2 time series},
	url = {https://doi.org/10.1038%2Fs41598-020-74215-5},
	volume = {10},
	year = {2020}
}

@article{Carbonneau_2020,
	doi = {10.1016/j.rse.2020.112107},
	url = {https://doi.org/10.1016%2Fj.rse.2020.112107},
	year = 2020,
	month = {dec},
	publisher = {Elsevier {BV}},
	volume = {251},
	pages = {112107},
	author = {Patrice E. Carbonneau and Stephen J. Dugdale and Toby P. Breckon and James T. Dietrich and Mark A. Fonstad and Hitoshi Miyamoto and Amy S. Woodget},
	title = {Adopting deep learning methods for airborne {RGB} fluvial scene classification},
	journal = {Remote Sensing of Environment}
}

@inproceedings{Castro_2017,
	doi = {10.1109/sibgrapi.2017.57},
	url = {https://doi.org/10.1109%2Fsibgrapi.2017.57},
	year = 2017,
	month = {oct},
	publisher = {{IEEE}},
	author = {Jose David Bermudez Castro and Raul Queiroz Feitoza and Laura Cue La Rosa and Pedro Marco Achanccaray Diaz and Ieda Del Arco Sanches},
	title = {A Comparative Analysis of Deep Learning Techniques for Sub-Tropical Crop Types Recognition from Multitemporal Optical/{SAR} Image Sequences},
	booktitle = {2017 30th {SIBGRAPI} Conference on Graphics, Patterns and Images ({SIBGRAPI})}
}

@inproceedings{Charou_2019,
	doi = {10.1109/iisa.2019.8900670},
	url = {https://doi.org/10.1109%2Fiisa.2019.8900670},
	year = 2019,
	month = {jul},
	publisher = {{IEEE}},
	author = {Eleni Charou and George Felekis and Danai Bournou Stavroulopoulou and Maria Koutsoukou and Antigoni Panagiotopoulou and Yorghos Voutos and Emmanuel Bratsolis and Phivos Mylonas and Laurence Likforman-Sulem},
	title = {Deep Learning for Agricultural Land Detection in Insular Areas},
	booktitle = {2019 10th International Conference on Information, Intelligence, Systems and Applications ({IISA})}
}

@article{Chatterjee_2020,
	doi = {10.1109/lgrs.2020.2993095},
	url = {https://doi.org/10.1109%2Flgrs.2020.2993095},
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	pages = {1--5},
	author = {Ankita Chatterjee and Jayasree Saha and Jayanta Mukherjee and Subhas Aikat and Arundhati Misra},
	title = {Unsupervised Land Cover Classification of Hybrid and Dual-Polarized Images Using Deep Convolutional Neural Network},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@article{Chen_2014,
	doi = {10.1109/jstars.2014.2329330},
	url = {https://doi.org/10.1109%2Fjstars.2014.2329330},
	year = 2014,
	month = {jun},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {7},
	number = {6},
	pages = {2094--2107},
	author = {Yushi Chen and Zhouhan Lin and Xing Zhao and Gang Wang and Yanfeng Gu},
	title = {Deep Learning-Based Classification of Hyperspectral Data},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Chen_2020,
	doi = {10.1109/jstars.2019.2954130},
	url = {https://doi.org/10.1109%2Fjstars.2019.2954130},
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {13},
	pages = {143--153},
	author = {Yang Chen and Luliang Tang and Xue Yang and Rongshuang Fan and Muhammad Bilal and Qingquan Li},
	title = {Thick Clouds Removal From Multitemporal {ZY}-3 Satellite Images Using Deep Learning},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Choe_2019,
	doi = {10.1007/s41324-019-00299-5},
	url = {https://doi.org/10.1007%2Fs41324-019-00299-5},
	year = 2019,
	month = {nov},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {28},
	number = {3},
	pages = {377--382},
	author = {Yu-Jeong Choe and Jae-Hong Yom},
	title = {Improving accuracy of land surface temperature prediction model based on deep-learning},
	journal = {Spat. Inf. Res.}
}

@article{Civco_1993,
	doi = {10.1080/02693799308901949},
	url = {https://doi.org/10.1080%2F02693799308901949},
	year = 1993,
	month = {mar},
	publisher = {Informa {UK} Limited},
	volume = {7},
	number = {2},
	pages = {173--186},
	author = {Daniel L. Civco},
	title = {Artificial neural networks for land-cover classification and mapping},
	journal = {International journal of geographical information systems}
}

@article{DeLancey_2019,
	abstract = {<jats:p>Advances in machine learning have changed many fields of study and it has also drawn attention in a variety of remote sensing applications. In particular, deep convolutional neural networks (CNNs) have proven very useful in fields such as image recognition; however, the use of CNNs in large-scale remote sensing landcover classifications still needs further investigation. We set out to test CNN-based landcover classification against a more conventional XGBoost shallow learning algorithm for mapping a notoriously difficult group of landcover classes, wetland class as defined by the Canadian Wetland Classification System. We developed two wetland inventory style products for a large (397,958 km2) area in the Boreal Forest region of Alberta, Canada, using Sentinel-1, Sentinel-2, and ALOS DEM data acquired in Google Earth Engine. We then tested the accuracy of these two products against three validation data sets (two photo-interpreted and one field). The CNN-generated wetland product proved to be more accurate than the shallow learning XGBoost wetland product by 5%. The overall accuracy of the CNN product was 80.2% with a mean F1-score of 0.58. We believe that CNNs are better able to capture natural complexities within wetland classes, and thus may be very useful for complex landcover classifications. Overall, this CNN framework shows great promise for generating large-scale wetland inventory data and may prove useful for other landcover mapping applications.</jats:p>},
	author = {Evan R. DeLancey and John F. Simms and Masoud Mahdianpari and Brian Brisco and Craig Mahoney and Jahan Kariyeva},
	doi = {10.3390/rs12010002},
	journal = {Remote Sensing},
	month = {dec},
	number = {1},
	pages = {2},
	publisher = {{MDPI} {AG}},
	title = {Comparing Deep Learning and Shallow Learning for Large-Scale Wetland Classification in Alberta, Canada},
	url = {https://doi.org/10.3390%2Frs12010002},
	volume = {12},
	year = {2019}
}

@article{Ding_2020,
	doi = {10.1007/s12517-020-05487-4},
	url = {https://doi.org/10.1007%2Fs12517-020-05487-4},
	year = 2020,
	month = {jun},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {13},
	number = {12},
	author = {Haiyong Ding and Luming Xu and Yue Wu and Wenzhong Shi},
	title = {Classification of hyperspectral images by deep learning of spectral-spatial features},
	journal = {Arab J Geosci}
}

@article{Dong_2020,
	doi = {10.1109/jstars.2019.2953234},
	url = {https://doi.org/10.1109%2Fjstars.2019.2953234},
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {13},
	pages = {113--128},
	author = {Luofan Dong and Huaqiang Du and Fangjie Mao and Ning Han and Xuejian Li and Guomo Zhou and Di{\textquotesingle}en Zhu and Junlong Zheng and Meng Zhang and Luqi Xing and Tengyan Liu},
	title = {Very High Resolution Remote Sensing Imagery Classification Using a Fusion of Random Forest and Deep Learning Technique{\textemdash}Subtropical Area for Example},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{El_Mendili_2020,
	abstract = {<jats:p>The major part of the population lives in urban areas, and this is expected to increase in the future. The main challenges faced by cities currently and towards the future are the rapid urbanization, the increase in urban temperature and the urban heat island. Mapping and monitoring urban fabric (UF) to analyze the environmental impact of these phenomena is more necessary than ever. This coupled with the increased availability of Earth observation data and their growing temporal capabilities leads us to consider using temporal features for improving land use classification, especially in urban environments where the spectral overlap between classes makes it challenging. Urban land use classification thus remains a central question in remote sensing. Although some research studies have successfully used multi-temporal images such as Landsat-8 or Sentinel-2 to improve land cover classification, urban land use mapping is rarely carried using the temporal dimension. This paper explores the use of Sentinel-2 data in a deep learning framework, by firstly assessing the temporal robustness of four popular fully convolutional neural networks (FCNs) trained over single-date images for the classification of the urban footprint, and secondly, by proposing a multi-temporal FCN. A performance comparison between the proposed framework and a regular FCN is also conducted. In this study, we consider four UF classes typical of many European Western cities. Results show that training the proposed multi-date model on Sentinel 2 multi-temporal data achieved the best results with a Kappa coefficient increase of 2.72% and 6.40%, respectively for continuous UF and industrial facilities. Although a more definitive conclusion requires further testing, first results are promising because they confirm that integrating the temporal dimension with a high spatial resolution into urban land use classification may be a valuable strategy to discriminate among several urban categories.</jats:p>},
	author = {Lamiae El Mendili and Anne Puissant and Mehdi Chougrad and Imane Sebari},
	doi = {10.3390/rs12030423},
	journal = {Remote Sensing},
	month = {jan},
	number = {3},
	pages = {423},
	publisher = {{MDPI} {AG}},
	title = {Towards a Multi-Temporal Deep Learning Approach for Mapping Urban Fabric Using Sentinel 2 Images},
	url = {https://doi.org/10.3390%2Frs12030423},
	volume = {12},
	year = {2020}
}

@article{G_mez_2016,
	doi = {10.1016/j.isprsjprs.2016.03.008},
	url = {https://doi.org/10.1016%2Fj.isprsjprs.2016.03.008},
	year = 2016,
	month = {jun},
	publisher = {Elsevier {BV}},
	volume = {116},
	pages = {55--72},
	author = {Cristina G{\'{o}}mez and Joanne C. White and Michael A. Wulder},
	title = {Optical remotely sensed time series data for land cover classification: A review},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing} # Journal # of # Photogrammetry # and # Remote # Sensing
}

@article{Garc_a_Rodr_guez_2020,
	abstract = {<jats:p>In recent years, different deep learning techniques were applied to segment aerial and satellite images. Nevertheless, state of the art techniques for land cover segmentation does not provide accurate results to be used in real applications. This is a problem faced by institutions and companies that want to replace time-consuming and exhausting human work with AI technology. In this work, we propose a method that combines deep learning with a human-in-the-loop strategy to achieve expert-level results at a low cost. We use a neural network to segment the images. In parallel, another network is used to measure uncertainty for predicted pixels. Finally, we combine these neural networks with a human-in-the-loop approach to produce correct predictions as if developed by human photointerpreters. Applying this methodology shows that we can increase the accuracy of land cover segmentation tasks while decreasing human intervention.</jats:p>},
	author = {Carlos Garc{\'{\i}}a Rodr{\'{\i}}guez and Jordi Vitri{\`{a}} and Oscar Mora},
	doi = {10.3390/rs12223836},
	journal = {Remote Sensing},
	month = {nov},
	number = {22},
	pages = {3836},
	publisher = {{MDPI} {AG}},
	title = {Uncertainty-Based Human-in-the-Loop Deep Learning for Land Cover Segmentation},
	url = {https://doi.org/10.3390%2Frs12223836},
	volume = {12},
	year = {2020}
}

@article{Gargees_2020,
	doi = {10.1109/lgrs.2019.2948799},
	url = {https://doi.org/10.1109%2Flgrs.2019.2948799},
	year = 2020,
	month = {aug},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {17},
	number = {8},
	pages = {1386--1390},
	author = {Rasha S. Gargees and Grant J. Scott},
	title = {Deep Feature Clustering for Remote Sensing Imagery Land Cover Analysis},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@inproceedings{Gargiulo_2019,
	doi = {10.1109/metroagrifor.2019.8909243},
	url = {https://doi.org/10.1109%2Fmetroagrifor.2019.8909243},
	year = 2019,
	month = {oct},
	publisher = {{IEEE}},
	author = {Massimiliano Gargiulo and Domenico A. G. Dell{\textquotesingle}Aglio and Antonio Iodice and Daniele Riccio and Giuseppe Ruello},
	title = {Semantic Segmentation using Deep Learning: A case of study in Albufera Park, Valencia},
	booktitle = {2019 {IEEE} International Workshop on Metrology for Agriculture and Forestry ({MetroAgriFor})}
}

@article{Gavade_2020,
	doi = {10.1007/s12065-020-00362-3},
	url = {https://doi.org/10.1007%2Fs12065-020-00362-3},
	year = 2020,
	month = {feb},
	publisher = {Springer Science and Business Media {LLC}},
	author = {Anil B. Gavade and Vijay S. Rajpurohit},
	title = {Sparse-{FCM} and deep learning for effective classification of land area in multi-spectral satellite images},
	journal = {Evol. Intel.}
}

@article{Ghamisi_2018,
	doi = {10.1109/mgrs.2018.2854840},
	url = {https://doi.org/10.1109%2Fmgrs.2018.2854840},
	year = 2018,
	month = {sep},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {6},
	number = {3},
	pages = {10--43},
	author = {Pedram Ghamisi and Emmanuel Maggiori and Shutao Li and Roberto Souza and Yuliya Tarablaka and Gabriele Moser and Andrea De Giorgi and Leyuan Fang and Yushi Chen and Mingmin Chi and Sebastiano B. Serpico and Jon Atli Benediktsson},
	title = {New Frontiers in Spectral-Spatial Hyperspectral Image Classification: The Latest Advances Based on Mathematical Morphology, Markov Random Fields, Segmentation, Sparse Representation, and Deep Learning},
	journal = {IEEE Geosci. Remote Sens. Mag.} # Geoscience # and # Remote # Sensing # Magazine
}

@article{Guirado_2017,
	doi = {10.3390/rs9121220},
	url = {https://doi.org/10.3390%2Frs9121220},
	year = 2017,
	month = {nov},
	publisher = {{MDPI} {AG}},
	volume = {9},
	number = {12},
	pages = {1220},
	author = {Emilio Guirado and Siham Tabik and Domingo Alcaraz-Segura and Javier Cabello and Francisco Herrera},
	title = {Deep-learning Versus {OBIA} for Scattered Shrub Detection with Google Earth Imagery: Ziziphus lotus as Case Study},
	journal = {Remote Sensing}
}

@article{Guirado_2020,
	abstract = {<jats:p>Accurate tree cover mapping is of paramount importance in many fields, from biodiversity conservation to carbon stock estimation, ecohydrology, erosion control, or Earth system modelling. Despite this importance, there is still uncertainty about global forest cover, particularly in drylands. Recently, the Food and Agriculture Organization of the United Nations (FAO) conducted a costly global assessment of dryland forest cover through the visual interpretation of orthoimages using the Collect Earth software, involving hundreds of operators from around the world. Our study proposes a new automatic method for estimating tree cover using artificial intelligence and free orthoimages. Our results show that our tree cover classification model, based on convolutional neural networks (CNN), is 23% more accurate than the manual visual interpretation used by FAO, reaching up to 79% overall accuracy. The smallest differences between the two methods occurred in the driest regions, but disagreement increased with the percentage of tree cover. The application of CNNs could be used to improve and reduce the cost of tree cover maps from the local to the global scale, with broad implications for research and management.</jats:p>},
	author = {Emilio Guirado and Domingo Alcaraz-Segura and Javier Cabello and Sergio Puertas-Ru{\'{\i}}z and Francisco Herrera and Siham Tabik},
	doi = {10.3390/rs12030343},
	journal = {Remote Sensing},
	month = {jan},
	number = {3},
	pages = {343},
	publisher = {{MDPI} {AG}},
	title = {Tree Cover Estimation in Global Drylands from Space Using Deep Learning},
	url = {https://doi.org/10.3390%2Frs12030343},
	volume = {12},
	year = {2020}
}

@inproceedings{Guo_2017,
	doi = {10.1109/bigsardata.2017.8124926},
	url = {https://doi.org/10.1109%2Fbigsardata.2017.8124926},
	year = 2017,
	month = {nov},
	publisher = {{IEEE}},
	author = {Yujuan Guo and Erxue Chen and Ying Guo and Zengyuan Li and Chonggui Li and Kunpeng Xu},
	title = {Deep highway unit network for land cover type classification with {GF}-3 {SAR} imagery},
	booktitle = {2017 {SAR} in Big Data Era: Models, Methods and Applications ({BIGSARDATA})}
}

@article{Han_2020,
	abstract = {<jats:p>Land cover is an important variable of the terrestrial ecosystem that provides information for natural resources management, urban sprawl detection, and environment research. To classify land cover with high-spatial-resolution multispectral remote sensing imagery is a difficult problem due to heterogeneous spectral values of the same object on the ground. Fully convolutional networks (FCNs) are a state-of-the-art method that has been increasingly used in image segmentation and classification. However, a systematic quantitative comparison of FCNs on high-spatial-multispectral remote imagery was not yet performed. In this paper, we adopted the three FCNs (FCN-8s, Segnet, and Unet) for Gaofen-2 (GF2) satellite imagery classification. Two scenes of GF2 with a total of 3329 polygon samples were used in the study area and a systematic quantitative comparison of FCNs was conducted with red, green, blue (RGB) and RGB+near infrared (NIR) inputs for GF2 satellite imagery. The results showed that: (1) The FCN methods perform well in land cover classification with GF2 imagery, and yet, different FCNs architectures exhibited different results in mapping accuracy. The FCN-8s model performed best among the Segnet and Unet architectures due to the multiscale feature channels in the upsampling stage. Averaged across the models, the overall accuracy (OA) and Kappa coefficient (Kappa) were 5% and 0.06 higher, respectively, in FCN-8s when compared with the other two models. (2) High-spatial-resolution remote sensing imagery with RGB+NIR bands performed better than RGB input at mapping land cover, and yet the advantage was limited; the OA and Kappa only increased an average of 0.4% and 0.01 in the RGB+NIR bands. (3) The GF2 imagery provided an encouraging result in estimating land cover based on the FCN-8s method, which can be exploited for large-scale land cover mapping in the future.</jats:p>},
	author = {Zemin Han and Yuanyong Dian and Hao Xia and Jingjing Zhou and Yongfeng Jian and Chonghuai Yao and Xiong Wang and Yuan Li},
	doi = {10.3390/ijgi9080478},
	journal = {IJGI} # International # Journal # of # Geo-Information
}

@article{He_2020,
	doi = {10.1007/s11227-020-03377-w},
	url = {https://doi.org/10.1007%2Fs11227-020-03377-w},
	year = 2020,
	month = {jul},
	publisher = {Springer Science and Business Media {LLC}},
	author = {Tongdi He and Shengxin Wang},
	title = {Multi-spectral remote sensing land-cover classification based on deep learning methods},
	journal = {J Supercomput}
}

@inproceedings{Helber_2018,
	doi = {10.1109/igarss.2018.8519248},
	url = {https://doi.org/10.1109%2Figarss.2018.8519248},
	year = 2018,
	month = {jul},
	publisher = {{IEEE}},
	author = {Patrick Helber and Benjamin Bischke and Andreas Dengel and Damian Borth},
	title = {Introducing Eurosat: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification},
	booktitle = {{IGARSS} 2018 - 2018 {IEEE} International Geoscience and Remote Sensing Symposium}
}

@article{Helber_2019,
	doi = {10.1109/jstars.2019.2918242},
	url = {https://doi.org/10.1109%2Fjstars.2019.2918242},
	year = 2019,
	month = {jul},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {12},
	number = {7},
	pages = {2217--2226},
	author = {Patrick Helber and Benjamin Bischke and Andreas Dengel and Damian Borth},
	title = {{EuroSAT}: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Helbich_2019,
	doi = {10.1016/j.envint.2019.02.013},
	url = {https://doi.org/10.1016%2Fj.envint.2019.02.013},
	year = 2019,
	month = {may},
	publisher = {Elsevier {BV}},
	volume = {126},
	pages = {107--117},
	author = {Marco Helbich and Yao Yao and Ye Liu and Jinbao Zhang and Penghua Liu and Ruoyu Wang},
	title = {Using deep learning to examine street view green and blue spaces and their associations with geriatric depression in Beijing, China},
	journal = {Environment International}
}

@article{Hoxha_2020,
	doi = {10.1109/jstars.2020.3013818},
	url = {https://doi.org/10.1109%2Fjstars.2020.3013818},
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {13},
	pages = {4462--4475},
	author = {Genc Hoxha and Farid Melgani and Begum Demir},
	title = {Toward Remote Sensing Image Retrieval Under a Deep Image Captioning Perspective},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Hu_2018,
	abstract = {<jats:p>Land cover and its dynamic information is the basis for characterizing surface conditions, supporting land resource management and optimization, and assessing the impacts of climate change and human activities. In land cover information extraction, the traditional convolutional neural network (CNN) method has several problems, such as the inability to be applied to multispectral and hyperspectral satellite imagery, the weak generalization ability of the model and the difficulty of automating the construction of a training database. To solve these problems, this study proposes a new type of deep convolutional neural network based on Landsat-8 Operational Land Imager (OLI) imagery. The network integrates cascaded cross-channel parametric pooling and average pooling layer, applies a hierarchical sampling strategy to realize the automatic construction of the training dataset, determines the technical scheme of model-related parameters, and finally performs the automatic classification of remote sensing images. This study used the new type of deep convolutional neural network to extract land cover information from Qinhuangdao City, Hebei Province, and compared the experimental results with those obtained by traditional methods. The results show that: (1) The proposed deep convolutional neural network (DCNN) model can automatically construct the training dataset and classify images. This model performs the classification of multispectral and hyperspectral satellite images using deep neural networks, which improves the generalization ability of the model and simplifies the application of the model. (2) The proposed DCNN model provides the best classification results in the Qinhuangdao area. The overall accuracy of the land cover data obtained is 82.0%, and the kappa coefficient is 0.76. The overall accuracy is improved by 5% and 14% compared to the support vector machine method and the maximum likelihood classification method, respectively.</jats:p>},
	author = {Yunfeng Hu and Qianli Zhang and Yunzhi Zhang and Huimin Yan},
	doi = {10.3390/rs10122053},
	journal = {Remote Sensing},
	month = {dec},
	number = {12},
	pages = {2053},
	publisher = {{MDPI} {AG}},
	title = {A Deep Convolution Neural Network Method for Land Cover Mapping: A Case Study of Qinhuangdao, China},
	url = {https://doi.org/10.3390%2Frs10122053},
	volume = {10},
	year = {2018}
}

@article{Huang_2021,
	doi = {10.1109/lgrs.2020.2965558},
	url = {https://doi.org/10.1109%2Flgrs.2020.2965558},
	year = 2021,
	month = {jan},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {18},
	number = {1},
	pages = {107--111},
	author = {Zhongling Huang and Corneliu Octavian Dumitru and Zongxu Pan and Bin Lei and Mihai Datcu},
	title = {Classification of Large-Scale High-Resolution {SAR} Images With Deep Transfer Learning},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@article{Ienco_2017,
	doi = {10.1109/lgrs.2017.2728698},
	url = {https://doi.org/10.1109%2Flgrs.2017.2728698},
	year = 2017,
	month = {oct},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {14},
	number = {10},
	pages = {1685--1689},
	author = {Dino Ienco and Raffaele Gaetano and Claire Dupaquier and Pierre Maurel},
	title = {Land Cover Classification via Multitemporal Spatial Data by Deep Recurrent Neural Networks},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@article{Ienco_2019,
	doi = {10.1016/j.isprsjprs.2019.09.016},
	url = {https://doi.org/10.1016%2Fj.isprsjprs.2019.09.016},
	year = 2019,
	month = {dec},
	publisher = {Elsevier {BV}},
	volume = {158},
	pages = {11--22},
	author = {Dino Ienco and Roberto Interdonato and Raffaele Gaetano and Dinh Ho Tong Minh},
	title = {Combining Sentinel-1 and Sentinel-2 Satellite Image Time Series for land cover mapping via a multi-source deep learning architecture},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing} # Journal # of # Photogrammetry # and # Remote # Sensing
}

@article{Interdonato_2019,
	doi = {10.1016/j.isprsjprs.2019.01.011},
	url = {https://doi.org/10.1016%2Fj.isprsjprs.2019.01.011},
	year = 2019,
	month = {mar},
	publisher = {Elsevier {BV}},
	volume = {149},
	pages = {91--104},
	author = {Roberto Interdonato and Dino Ienco and Raffaele Gaetano and Kenji Ose},
	title = {{DuPLO}: A {DUal} view Point deep Learning architecture for time series {classificatiOn}},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing} # Journal # of # Photogrammetry # and # Remote # Sensing
}

@article{Isikdogan_2017,
	doi = {10.1109/jstars.2017.2735443},
	url = {https://doi.org/10.1109%2Fjstars.2017.2735443},
	year = 2017,
	month = {nov},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {10},
	number = {11},
	pages = {4909--4918},
	author = {Furkan Isikdogan and Alan C. Bovik and Paola Passalacqua},
	title = {Surface Water Mapping by Deep Learning},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Jakovljevic_2019,
	abstract = {<jats:p>Digital elevation model (DEM) has been frequently used for the reduction and management of flood risk. Various classification methods have been developed to extract DEM from point clouds. However, the accuracy and computational efficiency need to be improved. The objectives of this study were as follows: (1) to determine the suitability of a new method to produce DEM from unmanned aerial vehicle (UAV) and light detection and ranging (LiDAR) data, using a raw point cloud classification and ground point filtering based on deep learning and neural networks (NN); (2) to test the convenience of rebalancing datasets for point cloud classification; (3) to evaluate the effect of the land cover class on the algorithm performance and the elevation accuracy; and (4) to assess the usability of the LiDAR and UAV structure from motion (SfM) DEM in flood risk mapping. In this paper, a new method of raw point cloud classification and ground point filtering based on deep learning using NN is proposed and tested on LiDAR and UAV data. The NN was trained on approximately 6 million points from which local and global geometric features and intensity data were extracted. Pixel-by-pixel accuracy assessment and visual inspection confirmed that filtering point clouds based on deep learning using NN is an appropriate technique for ground classification and producing DEM, as for the test and validation areas, both ground and non-ground classes achieved high recall (&gt;0.70) and high precision values (&gt;0.85), which showed that the two classes were well handled by the model. The type of method used for balancing the original dataset did not have a significant influence in the algorithm accuracy, and it was suggested not to use any of them unless the distribution of the generated and real data set will remain the same. Furthermore, the comparisons between true data and LiDAR and a UAV structure from motion (UAV SfM) point clouds were analyzed, as well as the derived DEM. The root mean square error (RMSE) and the mean average error (MAE) of the DEM were 0.25 m and 0.05 m, respectively, for LiDAR data, and 0.59 m and –0.28 m, respectively, for UAV data. For all land cover classes, the UAV DEM overestimated the elevation, whereas the LIDAR DEM underestimated it. The accuracy was not significantly different in the LiDAR DEM for the different vegetation classes, while for the UAV DEM, the RMSE increased with the height of the vegetation class. The comparison of the inundation areas derived from true LiDAR and UAV data for different water levels showed that in all cases, the largest differences were obtained for the lowest water level tested, while they performed best for very high water levels. Overall, the approach presented in this work produced DEM from LiDAR and UAV data with the required accuracy for flood mapping according to European Flood Directive standards. Although LiDAR is the recommended technology for point cloud acquisition, a suitable alternative is also UAV SfM in hilly areas.</jats:p>},
	author = {Gordana Jakovljevic and Miro Govedarica and Flor Alvarez-Taboada and Vladimir Pajic},
	doi = {10.3390/geosciences9070323},
	journal = {Geosciences},
	month = {jul},
	number = {7},
	pages = {323},
	publisher = {{MDPI} {AG}},
	title = {Accuracy Assessment of Deep Learning Based Classification of {LiDAR} and {UAV} Points Clouds for {DTM} Creation and Flood Risk Mapping},
	url = {https://doi.org/10.3390%2Fgeosciences9070323},
	volume = {9},
	year = {2019}
}

@article{Jia_2020,
	abstract = {<jats:p>Spatiotemporal fusion is considered a feasible and cost-effective way to solve the trade-off between the spatial and temporal resolution of satellite sensors. Recently proposed learning-based spatiotemporal fusion methods can address the prediction of both phenological and land-cover change. In this paper, we propose a novel deep learning-based spatiotemporal data fusion method that uses a two-stream convolutional neural network. The method combines both forward and backward prediction to generate a target fine image, where temporal change-based and a spatial information-based mapping are simultaneously formed, addressing the prediction of both phenological and land-cover changes with better generalization ability and robustness. Comparative experimental results for the test datasets with phenological and land-cover changes verified the effectiveness of our method. Compared to existing learning-based spatiotemporal fusion methods, our method is more effective in predicting phenological change and directly reconstructing the prediction with complete spatial details without the need for auxiliary modulation.</jats:p>},
	author = {Duo Jia and Changqing Song and Changxiu Cheng and Shi Shen and Lixin Ning and Chun Hui},
	doi = {10.3390/rs12040698},
	journal = {Remote Sensing},
	month = {feb},
	number = {4},
	pages = {698},
	publisher = {{MDPI} {AG}},
	title = {A Novel Deep Learning-Based Spatiotemporal Fusion Method for Combining Satellite Images with Different Resolutions Using a Two-Stream Convolutional Neural Network},
	url = {https://doi.org/10.3390%2Frs12040698},
	volume = {12},
	year = {2020}
}

@article{Jin_2019,
	doi = {10.1007/s12524-019-00945-3},
	url = {https://doi.org/10.1007%2Fs12524-019-00945-3},
	year = 2019,
	month = {jan},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {47},
	number = {6},
	pages = {951--965},
	author = {Baoxuan Jin and Peng Ye and Xueying Zhang and Weiwei Song and Shihua Li},
	title = {Object-Oriented Method Combined with Deep Convolutional Neural Networks for Land-Use-Type Classification of Remote Sensing Images},
	journal = {J Indian Soc Remote Sens}
}

@article{Jozdani_2019,
	abstract = {<jats:p>With the advent of high-spatial resolution (HSR) satellite imagery, urban land use/land cover (LULC) mapping has become one of the most popular applications in remote sensing. Due to the importance of context information (e.g., size/shape/texture) for classifying urban LULC features, Geographic Object-Based Image Analysis (GEOBIA) techniques are commonly employed for mapping urban areas. Regardless of adopting a pixel- or object-based framework, the selection of a suitable classifier is of critical importance for urban mapping. The popularity of deep learning (DL) (or deep neural networks (DNNs)) for image classification has recently skyrocketed, but it is still arguable if, or to what extent, DL methods can outperform other state-of-the art ensemble and/or Support Vector Machines (SVM) algorithms in the context of urban LULC classification using GEOBIA. In this study, we carried out an experimental comparison among different architectures of DNNs (i.e., regular deep multilayer perceptron (MLP), regular autoencoder (RAE), sparse, autoencoder (SAE), variational autoencoder (AE), convolutional neural networks (CNN)), common ensemble algorithms (Random Forests (RF), Bagging Trees (BT), Gradient Boosting Trees (GB), and Extreme Gradient Boosting (XGB)), and SVM to investigate their potential for urban mapping using a GEOBIA approach. We tested the classifiers on two RS images (with spatial resolutions of 30 cm and 50 cm). Based on our experiments, we drew three main conclusions: First, we found that the MLP model was the most accurate classifier. Second, unsupervised pretraining with the use of autoencoders led to no improvement in the classification result. In addition, the small difference in the classification accuracies of MLP from those of other models like SVM, GB, and XGB classifiers demonstrated that other state-of-the-art machine learning classifiers are still versatile enough to handle mapping of complex landscapes. Finally, the experiments showed that the integration of CNN and GEOBIA could not lead to more accurate results than the other classifiers applied.</jats:p>},
	author = {Shahab Eddin Jozdani and Brian Alan Johnson and Dongmei Chen},
	doi = {10.3390/rs11141713},
	journal = {Remote Sensing},
	month = {jul},
	number = {14},
	pages = {1713},
	publisher = {{MDPI} {AG}},
	title = {Comparing Deep Neural Networks, Ensemble Classifiers, and Support Vector Machine Algorithms for Object-Based Urban Land Use/Land Cover Classification},
	url = {https://doi.org/10.3390%2Frs11141713},
	volume = {11},
	year = {2019}
}

@article{Kalinicheva_2020,
	doi = {10.1109/jstars.2020.2982631},
	url = {https://doi.org/10.1109%2Fjstars.2020.2982631},
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {13},
	pages = {1450--1466},
	author = {Ekaterina Kalinicheva and Dino Ienco and Jeremie Sublime and Maria Trocan},
	title = {Unsupervised Change Detection Analysis in Satellite Image Time Series Using Deep Learning Combined With Graph-Based Approaches},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Kamilaris_2018,
	doi = {10.1016/j.compag.2018.02.016},
	url = {https://doi.org/10.1016%2Fj.compag.2018.02.016},
	year = 2018,
	month = {apr},
	publisher = {Elsevier {BV}},
	volume = {147},
	pages = {70--90},
	author = {Andreas Kamilaris and Francesc X. Prenafeta-Bold{\'{u}}},
	title = {Deep learning in agriculture: A survey},
	journal = {Computers and Electronics in Agriculture}
}

@inproceedings{Kampffmeyer_2017,
	doi = {10.1109/igarss.2017.8128164},
	url = {https://doi.org/10.1109%2Figarss.2017.8128164},
	year = 2017,
	month = {jul},
	publisher = {{IEEE}},
	author = {Michael Kampffmeyer and Arnt-Borre Salberg and Robert Jenssen},
	title = {Urban land cover classification with missing data using deep convolutional neural networks},
	booktitle = {2017 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})}
}

@article{Kampffmeyer_2018,
	doi = {10.1109/jstars.2018.2834961},
	url = {https://doi.org/10.1109%2Fjstars.2018.2834961},
	year = 2018,
	month = {jun},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {11},
	number = {6},
	pages = {1758--1768},
	author = {Michael Kampffmeyer and Arnt-Borre Salberg and Robert Jenssen},
	title = {Urban Land Cover Classification With Missing Data Modalities Using Deep Convolutional Neural Networks},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@inproceedings{Kussul_2016,
	doi = {10.1109/igarss.2016.7729043},
	url = {https://doi.org/10.1109%2Figarss.2016.7729043},
	year = 2016,
	month = {jul},
	publisher = {{IEEE}},
	author = {Nataliia Kussul and Andrii Shelestov and Mykola Lavreniuk and Igor Butko and Sergii Skakun},
	title = {Deep learning approach for large scale land cover mapping based on remote sensing data fusion},
	booktitle = {2016 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})}
}

@article{Kussul_2017,
	doi = {10.1109/lgrs.2017.2681128},
	url = {https://doi.org/10.1109%2Flgrs.2017.2681128},
	year = 2017,
	month = {may},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {14},
	number = {5},
	pages = {778--782},
	author = {Nataliia Kussul and Mykola Lavreniuk and Sergii Skakun and Andrii Shelestov},
	title = {Deep Learning Classification of Land Cover and Crop Types Using Remote Sensing Data},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@article{Kwan_2020,
	abstract = {<jats:p>There is an emerging interest in using hyperspectral data for land cover classification. The motivation behind using hyperspectral data is the notion that increasing the number of narrowband spectral channels would provide richer spectral information and thus help improve the land cover classification performance. Although hyperspectral data with hundreds of channels provide detailed spectral signatures, the curse of dimensionality might lead to degradation in the land cover classification performance. Moreover, in some practical applications, hyperspectral data may not be available due to cost, data storage, or bandwidth issues, and RGB and near infrared (NIR) could be the only image bands available for land cover classification. Light detection and ranging (LiDAR) data is another type of data to assist land cover classification especially if the land covers of interest have different heights. In this paper, we examined the performance of two Convolutional Neural Network (CNN)-based deep learning algorithms for land cover classification using only four bands (RGB+NIR) and five bands (RGB+NIR+LiDAR), where these limited number of image bands were augmented using Extended Multi-attribute Profiles (EMAP). The deep learning algorithms were applied to a well-known dataset used in the 2013 IEEE Geoscience and Remote Sensing Society (GRSS) Data Fusion Contest. With EMAP augmentation, the two deep learning algorithms were observed to achieve better land cover classification performance using only four bands as compared to that using all 144 hyperspectral bands.</jats:p>},
	author = {Chiman Kwan and Bulent Ayhan and Bence Budavari and Yan Lu and Daniel Perez and Jiang Li and Sergio Bernabe and Antonio Plaza},
	doi = {10.3390/rs12122000},
	journal = {Remote Sensing},
	month = {jun},
	number = {12},
	pages = {2000},
	publisher = {{MDPI} {AG}},
	title = {Deep Learning for Land Cover Classification Using Only a Few Bands},
	url = {https://doi.org/10.3390%2Frs12122000},
	volume = {12},
	year = {2020}
}

@inproceedings{Lavreniuk_2018,
	doi = {10.1109/igarss.2018.8518263},
	url = {https://doi.org/10.1109%2Figarss.2018.8518263},
	year = 2018,
	month = {jul},
	publisher = {{IEEE}},
	author = {Mykola Lavreniuk and Nataliia Kussul and Alexei Novikov},
	title = {Deep Learning Crop Classification Approach Based on Sparse Coding of Time Series of Satellite Data},
	booktitle = {{IGARSS} 2018 - 2018 {IEEE} International Geoscience and Remote Sensing Symposium}
}

@article{Li_2016,
	doi = {10.1080/01431161.2016.1246775},
	url = {https://doi.org/10.1080%2F01431161.2016.1246775},
	year = 2016,
	month = {oct},
	publisher = {Informa {UK} Limited},
	volume = {37},
	number = {23},
	pages = {5632--5646},
	author = {Weijia Li and Haohuan Fu and Le Yu and Peng Gong and Duole Feng and Congcong Li and Nicholas Clinton},
	title = {Stacked Autoencoder-based deep learning for remote-sensing image classification: a case study of African land-cover mapping},
	journal = {International Journal of Remote Sensing}
}

@article{Li_2019,
	doi = {10.1109/access.2019.2903127},
	url = {https://doi.org/10.1109%2Faccess.2019.2903127},
	year = 2019,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {7},
	pages = {36274--36284},
	author = {Wenmei Li and Haiyan Liu and Yu Wang and Zhuangzhuang Li and Yan Jia and Guan Gui},
	title = {Deep Learning-Based Classification Methods for Remote Sensing Images in Urban Built-Up Areas},
	journal = {IEEE Access} # Access
}

@article{Ling_2019,
	doi = {10.1080/2150704x.2019.1587196},
	url = {https://doi.org/10.1080%2F2150704x.2019.1587196},
	year = 2019,
	month = {mar},
	publisher = {Informa {UK} Limited},
	volume = {10},
	number = {6},
	pages = {598--606},
	author = {Feng Ling and Giles M. Foody},
	title = {Super-resolution land cover mapping by deep learning},
	journal = {Remote Sensing Letters}
}

@article{Liu_2018,
	doi = {10.1080/15481603.2018.1426091},
	url = {https://doi.org/10.1080%2F15481603.2018.1426091},
	year = 2018,
	month = {jan},
	publisher = {Informa {UK} Limited},
	volume = {55},
	number = {2},
	pages = {243--264},
	author = {Tao Liu and Amr Abd-Elrahman and Jon Morton and Victor L. Wilhelm},
	title = {Comparing fully convolutional networks, random forest, support vector machine, and patch-based deep convolutional neural networks for object-based wetland mapping using images from small unmanned aircraft system},
	journal = {GIScience & Remote Sensing} # {\&} # Remote # Sensing
}

@article{Liu_2019,
	doi = {10.1109/access.2019.2940527},
	url = {https://doi.org/10.1109%2Faccess.2019.2940527},
	year = 2019,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {7},
	pages = {128774--128786},
	author = {Yaohui Liu and Lutz Gross and Zhiqiang Li and Xiaoli Li and Xiwei Fan and Wenhua Qi},
	title = {Automatic Building Extraction on High-Resolution Remote Sensing Imagery Using Deep Convolutional Encoder-Decoder With Spatial Pyramid Pooling},
	journal = {IEEE Access} # Access
}

@article{Lv_2015,
	abstract = {<jats:p>Land use and land cover (LULC) mapping in urban areas is one of the core applications in remote sensing, and it plays an important role in modern urban planning and management. Deep learning is springing up in the field of machine learning recently. By mimicking the hierarchical structure of the human brain, deep learning can gradually extract features from lower level to higher level. The Deep Belief Networks (DBN) model is a widely investigated and deployed deep learning architecture. It combines the advantages of unsupervised and supervised learning and can archive good classification performance. This study proposes a classification approach based on the DBN model for detailed urban mapping using polarimetric synthetic aperture radar (PolSAR) data. Through the DBN model, effective contextual mapping features can be automatically extracted from the PolSAR data to improve the classification performance. Two-date high-resolution RADARSAT-2 PolSAR data over the Great Toronto Area were used for evaluation. Comparisons with the support vector machine (SVM), conventional neural networks (NN), and stochastic Expectation-Maximization (SEM) were conducted to assess the potential of the DBN-based classification approach. Experimental results show that the DBN-based method outperforms three other approaches and produces homogenous mapping results with preserved shape details.</jats:p>},
	author = {Qi Lv and Yong Dou and Xin Niu and Jiaqing Xu and Jinbo Xu and Fei Xia},
	doi = {10.1155/2015/538063},
	journal = {Journal of Sensors},
	pages = {1--10},
	publisher = {Hindawi Limited},
	title = {Urban Land Use and Land Cover Classification Using Remotely Sensed {SAR} Data through Deep Belief Networks},
	url = {https://doi.org/10.1155%2F2015%2F538063},
	volume = {2015},
	year = {2015}
}

@article{Lv_2018,
	doi = {10.1109/tii.2018.2873492},
	url = {https://doi.org/10.1109%2Ftii.2018.2873492},
	year = 2018,
	month = {dec},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {14},
	number = {12},
	pages = {5530--5538},
	author = {Ning Lv and Chen Chen and Tie Qiu and Arun Kumar Sangaiah},
	title = {Deep Learning and Superpixel Feature Extraction Based on Contractive Autoencoder for Change Detection in {SAR} Images},
	journal = {IEEE Trans. Ind. Inf.} # Transactions # on # Industrial # Informatics
}

@article{Lyu_2018,
	doi = {10.3390/rs10030471},
	url = {https://doi.org/10.3390%2Frs10030471},
	year = 2018,
	month = {mar},
	publisher = {{MDPI} {AG}},
	volume = {10},
	number = {3},
	pages = {471},
	author = {Haobo Lyu and Hui Lu and Lichao Mou and Wenyu Li and Jonathon Wright and Xuecao Li and Xinlu Li and Xiao Zhu and Jie Wang and Le Yu and Peng Gong},
	title = {Long-Term Annual Mapping of Four Cities on Different Continents by Applying a Deep Information Learning Method to Landsat Data},
	journal = {Remote Sensing}
}

@article{Ma_2017,
	doi = {10.1016/j.isprsjprs.2017.06.001},
	url = {https://doi.org/10.1016%2Fj.isprsjprs.2017.06.001},
	year = 2017,
	month = {aug},
	publisher = {Elsevier {BV}},
	volume = {130},
	pages = {277--293},
	author = {Lei Ma and Manchun Li and Xiaoxue Ma and Liang Cheng and Peijun Du and Yongxue Liu},
	title = {A review of supervised object-based land-cover image classification},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing} # Journal # of # Photogrammetry # and # Remote # Sensing
}

@article{Ma_2019,
	doi = {10.1016/j.isprsjprs.2019.04.015},
	url = {https://doi.org/10.1016%2Fj.isprsjprs.2019.04.015},
	year = 2019,
	month = {jun},
	publisher = {Elsevier {BV}},
	volume = {152},
	pages = {166--177},
	author = {Lei Ma and Yu Liu and Xueliang Zhang and Yuanxin Ye and Gaofei Yin and Brian Alan Johnson},
	title = {Deep learning in remote sensing applications: A meta-analysis and review},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing} # Journal # of # Photogrammetry # and # Remote # Sensing
}

@article{Mahdianpari_2018,
	abstract = {<jats:p>Despite recent advances of deep Convolutional Neural Networks (CNNs) in various computer vision tasks, their potential for classification of multispectral remote sensing images has not been thoroughly explored. In particular, the applications of deep CNNs using optical remote sensing data have focused on the classification of very high-resolution aerial and satellite data, owing to the similarity of these data to the large datasets in computer vision. Accordingly, this study presents a detailed investigation of state-of-the-art deep learning tools for classification of complex wetland classes using multispectral RapidEye optical imagery. Specifically, we examine the capacity of seven well-known deep convnets, namely DenseNet121, InceptionV3, VGG16, VGG19, Xception, ResNet50, and InceptionResNetV2, for wetland mapping in Canada. In addition, the classification results obtained from deep CNNs are compared with those based on conventional machine learning tools, including Random Forest and Support Vector Machine, to further evaluate the efficiency of the former to classify wetlands. The results illustrate that the full-training of convnets using five spectral bands outperforms the other strategies for all convnets. InceptionResNetV2, ResNet50, and Xception are distinguished as the top three convnets, providing state-of-the-art classification accuracies of 96.17%, 94.81%, and 93.57%, respectively. The classification accuracies obtained using Support Vector Machine (SVM) and Random Forest (RF) are 74.89% and 76.08%, respectively, considerably inferior relative to CNNs. Importantly, InceptionResNetV2 is consistently found to be superior compared to all other convnets, suggesting the integration of Inception and ResNet modules is an efficient architecture for classifying complex remote sensing scenes such as wetlands.</jats:p>},
	author = {Masoud Mahdianpari and Bahram Salehi and Mohammad Rezaee and Fariba Mohammadimanesh and Yun Zhang},
	doi = {10.3390/rs10071119},
	journal = {Remote Sensing},
	month = {jul},
	number = {7},
	pages = {1119},
	publisher = {{MDPI} {AG}},
	title = {Very Deep Convolutional Neural Networks for Complex Land Cover Mapping Using Multispectral Remote Sensing Imagery},
	url = {https://doi.org/10.3390%2Frs10071119},
	volume = {10},
	year = {2018}
}

@article{Manogaran_2020,
	doi = {10.1080/22797254.2020.1777802},
	url = {https://doi.org/10.1080%2F22797254.2020.1777802},
	year = 2020,
	month = {jun},
	publisher = {Informa {UK} Limited},
	volume = {53},
	number = {sup1},
	pages = {1--3},
	author = {Gunasekaran Manogaran and Hassan Qudrat-Ullah and Bharat S. Rawal Kshatriya},
	title = {Introduction to the special issue on deep learning for remote sensing environments},
	journal = {European Journal of Remote Sensing}
}

@article{Mehra_2020,
	doi = {10.1080/10106049.2019.1704072},
	url = {https://doi.org/10.1080%2F10106049.2019.1704072},
	year = 2020,
	month = {feb},
	publisher = {Informa {UK} Limited},
	pages = {1--16},
	author = {Aryan Mehra and Nihal Jain and Hari Shanker Srivastava},
	title = {A novel approach to use semantic segmentation based deep learning networks to classify multi-temporal {SAR} data},
	journal = {Geocarto International}
}

@inproceedings{Mei_2016,
	doi = {10.1109/igarss.2016.7730321},
	url = {https://doi.org/10.1109%2Figarss.2016.7730321},
	year = 2016,
	month = {jul},
	publisher = {{IEEE}},
	author = {Shaohui Mei and Jingyu Ji and Qianqian Bi and Junhui Hou and Qian Du and Wei Li},
	title = {Integrating spectral and spatial information into deep convolutional Neural Networks for hyperspectral classification},
	booktitle = {2016 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})}
}

@article{Meraner_2020,
	doi = {10.1016/j.isprsjprs.2020.05.013},
	url = {https://doi.org/10.1016%2Fj.isprsjprs.2020.05.013},
	year = 2020,
	month = {aug},
	publisher = {Elsevier {BV}},
	volume = {166},
	pages = {333--346},
	author = {Andrea Meraner and Patrick Ebel and Xiao Xiang Zhu and Michael Schmitt},
	title = {Cloud removal in Sentinel-2 imagery using a deep residual neural network and {SAR}-optical data fusion},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing} # Journal # of # Photogrammetry # and # Remote # Sensing
}

@article{Middel_2019,
	doi = {10.1016/j.landurbplan.2018.12.001},
	url = {https://doi.org/10.1016%2Fj.landurbplan.2018.12.001},
	year = 2019,
	month = {mar},
	publisher = {Elsevier {BV}},
	volume = {183},
	pages = {122--132},
	author = {Ariane Middel and Jonas Lukasczyk and Sophie Zakrzewski and Michael Arnold and Ross Maciejewski},
	title = {Urban form and composition of street canyons: A human-centric big data and deep learning approach},
	journal = {Landscape and Urban Planning}
}

@article{Mu_2019,
	doi = {10.1109/jstars.2019.2956318},
	url = {https://doi.org/10.1109%2Fjstars.2019.2956318},
	year = 2019,
	month = {dec},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {12},
	number = {12},
	pages = {5233--5247},
	author = {Lin Mu and Lizhe Wang and Yuewei Wang and Xiaodao Chen and Wei Han},
	title = {Urban Land Use and Land Cover Change Prediction via Self-Adaptive Cellular Based Deep Learning With Multisourced Data},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Narine_2019,
	abstract = {<jats:p>Spatially continuous estimates of forest aboveground biomass (AGB) are essential to supporting the sustainable management of forest ecosystems and providing invaluable information for quantifying and monitoring terrestrial carbon stocks. The launch of the Ice, Cloud, and land Elevation Satellite-2 (ICESat-2) on September 15th, 2018 offers an unparalleled opportunity to assess AGB at large scales using along-track samples that will be provided during its three-year mission. The main goal of this study was to investigate deep learning (DL) neural networks for mapping AGB with ICESat-2, using simulated photon-counting lidar (PCL)-estimated AGB for daytime, nighttime, and no noise scenarios, Landsat imagery, canopy cover, and land cover maps. The study was carried out in Sam Houston National Forest located in south-east Texas, using a simulated PCL-estimated AGB along two years of planned ICESat-2 profiles. The primary tasks were to investigate and determine neural network architecture, examine the hyper-parameter settings, and subsequently generate wall-to-wall AGB maps. A first set of models were developed using vegetation indices calculated from single-date Landsat imagery, canopy cover, and land cover, and a second set of models were generated using metrics from one year of Landsat imagery with canopy cover and land cover maps. To compare the effectiveness of final models, comparisons with Random Forests (RF) models were made. The deep neural network (DNN) models achieved R2 values of 0.42, 0.49, and 0.50 for the daytime, nighttime, and no noise scenarios respectively. With the extended dataset containing metrics calculated from Landsat images acquired on different dates, substantial improvements in model performance for all data scenarios were noted. The R2 values increased to 0.64, 0.66, and 0.67 for the daytime, nighttime, and no noise scenarios. Comparisons with Random forest (RF) prediction models highlighted similar results, with the same R2 and root mean square error (RMSE) range (15–16 Mg/ha) for daytime and nighttime scenarios. Findings suggest that there is potential for mapping AGB using a combinatory approach with ICESat-2 and Landsat-derived products with DL.</jats:p>},
	author = {Lana L. Narine and Sorin C. Popescu and Lonesome Malambo},
	doi = {10.3390/rs11121503},
	journal = {Remote Sensing},
	month = {jun},
	number = {12},
	pages = {1503},
	publisher = {{MDPI} {AG}},
	title = {Synergy of {ICESat}-2 and Landsat for Mapping Forest Aboveground Biomass with Deep Learning},
	url = {https://doi.org/10.3390%2Frs11121503},
	volume = {11},
	year = {2019}
}

@article{Ndikumana_2018,
	abstract = {<jats:p>The development and improvement of methods to map agricultural land cover are currently major challenges, especially for radar images. This is due to the speckle noise nature of radar, leading to a less intensive use of radar rather than optical images. The European Space Agency Sentinel-1 constellation, which recently became operational, is a satellite system providing global coverage of Synthetic Aperture Radar (SAR) with a 6-days revisit period at a high spatial resolution of about 20 m. These data are valuable, as they provide spatial information on agricultural crops. The aim of this paper is to provide a better understanding of the capabilities of Sentinel-1 radar images for agricultural land cover mapping through the use of deep learning techniques. The analysis is carried out on multitemporal Sentinel-1 data over an area in Camargue, France. The data set was processed in order to produce an intensity radar data stack from May 2017 to September 2017. We improved this radar time series dataset by exploiting temporal filtering to reduce noise, while retaining as much as possible the fine structures present in the images. We revealed that even with classical machine learning approaches (K nearest neighbors, random forest, and support vector machines), good performance classification could be achieved with F-measure/Accuracy greater than 86% and Kappa coefficient better than 0.82. We found that the results of the two deep recurrent neural network (RNN)-based classifiers clearly outperformed the classical approaches. Finally, our analyses of the Camargue area results show that the same performance was obtained with two different RNN-based classifiers on the Rice class, which is the most dominant crop of this region, with a F-measure metric of 96%. These results thus highlight that in the near future these RNN-based techniques will play an important role in the analysis of remote sensing time series.</jats:p>},
	author = {Emile Ndikumana and Dinh Ho Tong Minh and Nicolas Baghdadi and Dominique Courault and Laure Hossard},
	doi = {10.3390/rs10081217},
	journal = {Remote Sensing},
	month = {aug},
	number = {8},
	pages = {1217},
	publisher = {{MDPI} {AG}},
	title = {Deep Recurrent Neural Network for Agricultural Classification using multitemporal {SAR} Sentinel-1 for Camargue, France},
	url = {https://doi.org/10.3390%2Frs10081217},
	volume = {10},
	year = {2018}
}

@inproceedings{Nguyen_2018,
	doi = {10.1109/bigdata.2018.8621883},
	url = {https://doi.org/10.1109%2Fbigdata.2018.8621883},
	year = 2018,
	month = {dec},
	publisher = {{IEEE}},
	author = {Mai H. Nguyen and Jessica Block and Daniel Crawl and Vincent Siu and Akshit Bhatnagar and Federico Rodriguez and Alison Kwan and Namrita Baru and Ilkay Altintas},
	title = {Land Cover Classification at the Wildland Urban Interface using High-Resolution Satellite Imagery and Deep Learning},
	booktitle = {2018 {IEEE} International Conference on Big Data (Big Data)}
}

@inproceedings{Nijhawan_2017,
	doi = {10.1109/sitis.2017.41},
	url = {https://doi.org/10.1109%2Fsitis.2017.41},
	year = 2017,
	month = {dec},
	publisher = {{IEEE}},
	author = {Rahul Nijhawan and Himanshu Sharma and Harshita Sahni and Ashita Batra},
	title = {A Deep Learning Hybrid {CNN} Framework Approach for Vegetation Cover Mapping Using Deep Features},
	booktitle = {2017 13th International Conference on Signal-Image Technology {\&} Internet-Based Systems ({SITIS})}
}

@article{Nijhawan_2018,
	doi = {10.1080/01431161.2018.1519277},
	url = {https://doi.org/10.1080%2F01431161.2018.1519277},
	year = 2018,
	month = {sep},
	publisher = {Informa {UK} Limited},
	volume = {40},
	number = {2},
	pages = {759--773},
	author = {Rahul Nijhawan and Josodhir Das and Balasubramanian Raman},
	title = {A hybrid of deep learning and hand-crafted features based approach for snow cover mapping},
	journal = {International Journal of Remote Sensing}
}

@article{Parikh_2019,
	doi = {10.1080/19479832.2019.1655489},
	url = {https://doi.org/10.1080%2F19479832.2019.1655489},
	year = 2019,
	month = {aug},
	publisher = {Informa {UK} Limited},
	volume = {11},
	number = {1},
	pages = {1--32},
	author = {Hemani Parikh and Samir Patel and Vibha Patel},
	title = {Classification of {SAR} and {PolSAR} images using deep learning: a review},
	journal = {International Journal of Image and Data Fusion}
}

@article{Pashaei_2020,
	abstract = {<jats:p>Deep learning has already been proved as a powerful state-of-the-art technique for many image understanding tasks in computer vision and other applications including remote sensing (RS) image analysis. Unmanned aircraft systems (UASs) offer a viable and economical alternative to a conventional sensor and platform for acquiring high spatial and high temporal resolution data with high operational flexibility. Coastal wetlands are among some of the most challenging and complex ecosystems for land cover prediction and mapping tasks because land cover targets often show high intra-class and low inter-class variances. In recent years, several deep convolutional neural network (CNN) architectures have been proposed for pixel-wise image labeling, commonly called semantic image segmentation. In this paper, some of the more recent deep CNN architectures proposed for semantic image segmentation are reviewed, and each model’s training efficiency and classification performance are evaluated by training it on a limited labeled image set. Training samples are provided using the hyper-spatial resolution UAS imagery over a wetland area and the required ground truth images are prepared by manual image labeling. Experimental results demonstrate that deep CNNs have a great potential for accurate land cover prediction task using UAS hyper-spatial resolution images. Some simple deep learning architectures perform comparable or even better than complex and very deep architectures with remarkably fewer training epochs. This performance is especially valuable when limited training samples are available, which is a common case in most RS applications.</jats:p>},
	author = {Mohammad Pashaei and Hamid Kamangir and Michael J. Starek and Philippe Tissot},
	doi = {10.3390/rs12060959},
	journal = {Remote Sensing},
	month = {mar},
	number = {6},
	pages = {959},
	publisher = {{MDPI} {AG}},
	title = {Review and Evaluation of Deep Learning Architectures for Efficient Land Cover Mapping with {UAS} Hyper-Spatial Imagery: A Case Study Over a Wetland},
	url = {https://doi.org/10.3390%2Frs12060959},
	volume = {12},
	year = {2020}
}

@inproceedings{Pelletier_2019,
	doi = {10.1109/igarss.2019.8900123},
	url = {https://doi.org/10.1109%2Figarss.2019.8900123},
	year = 2019,
	month = {jul},
	publisher = {{IEEE}},
	author = {Charlotte Pelletier and Geoffrey I. Webb and Francois Petitjean},
	title = {Deep Learning for the Classification of Sentinel-2 Image Time Series},
	booktitle = {{IGARSS} 2019 - 2019 {IEEE} International Geoscience and Remote Sensing Symposium}
}

@article{Persello_2017,
	doi = {10.1109/lgrs.2017.2763738},
	url = {https://doi.org/10.1109%2Flgrs.2017.2763738},
	year = 2017,
	month = {dec},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {14},
	number = {12},
	pages = {2325--2329},
	author = {Claudio Persello and Alfred Stein},
	title = {Deep Fully Convolutional Networks for the Detection of Informal Settlements in {VHR} Images},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@inproceedings{Petersson_2016,
	doi = {10.1109/ipta.2016.7820963},
	url = {https://doi.org/10.1109%2Fipta.2016.7820963},
	year = 2016,
	month = {dec},
	publisher = {{IEEE}},
	author = {Henrik Petersson and David Gustafsson and David Bergstrom},
	title = {Hyperspectral image analysis using deep learning {\textemdash} A review},
	booktitle = {2016 Sixth International Conference on Image Processing Theory, Tools and Applications ({IPTA})}
}

@article{Poterek_2020,
	doi = {10.1109/jstars.2020.2992082},
	url = {https://doi.org/10.1109%2Fjstars.2020.2992082},
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {13},
	pages = {2899--2915},
	author = {Quentin Poterek and Pierre-Alexis Herrault and Grzegorz Skupinski and David Sheeren},
	title = {Deep Learning for Automatic Colorization of Legacy Grayscale Aerial Photographs},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@inproceedings{Pritt_2017,
	doi = {10.1109/aipr.2017.8457969},
	url = {https://doi.org/10.1109%2Faipr.2017.8457969},
	year = 2017,
	month = {oct},
	publisher = {{IEEE}},
	author = {Mark Pritt and Gary Chern},
	title = {Satellite Image Classification with Deep Learning},
	booktitle = {2017 {IEEE} Applied Imagery Pattern Recognition Workshop ({AIPR})}
}

@inproceedings{Qi_Lv_2014,
	doi = {10.1109/igarss.2014.6947537},
	url = {https://doi.org/10.1109%2Figarss.2014.6947537},
	year = 2014,
	month = {jul},
	publisher = {{IEEE}},
	author = {Qi Lv and  Yong Dou and  Xin Niu and  Jiaqing Xu and  Baoliang Li},
	title = {Classification of land cover based on deep belief networks using polarimetric {RADARSAT}-2 data},
	booktitle = {2014 {IEEE} Geoscience and Remote Sensing Symposium}
}

@inproceedings{Ramanath_2019,
	doi = {10.1109/igarss.2019.8900165},
	url = {https://doi.org/10.1109%2Figarss.2019.8900165},
	year = 2019,
	month = {jul},
	publisher = {{IEEE}},
	author = {Anushree Ramanath and Saipreethi Muthusrinivasan and Yiqun Xie and Shashi Shekhar and Bharathkumar Ramachandra},
	title = {{NDVI} Versus {CNN} Features in Deep Learning for Land Cover Clasification of Aerial Images},
	booktitle = {{IGARSS} 2019 - 2019 {IEEE} International Geoscience and Remote Sensing Symposium}
}

@article{Reichstein_2019,
	doi = {10.1038/s41586-019-0912-1},
	url = {https://doi.org/10.1038%2Fs41586-019-0912-1},
	year = 2019,
	month = {feb},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {566},
	number = {7743},
	pages = {195--204},
	author = {Markus Reichstein and Gustau Camps-Valls and Bjorn Stevens and Martin Jung and Joachim Denzler and Nuno Carvalhais and  Prabhat},
	title = {Deep learning and process understanding for data-driven Earth system science},
	journal = {Nature}
}

@article{Rezaee_2018,
	doi = {10.1109/jstars.2018.2846178},
	url = {https://doi.org/10.1109%2Fjstars.2018.2846178},
	year = 2018,
	month = {sep},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {11},
	number = {9},
	pages = {3030--3039},
	author = {Mohammad Rezaee and Masoud Mahdianpari and Yun Zhang and Bahram Salehi},
	title = {Deep Convolutional Neural Network for Complex Wetland Classification Using Optical Remote Sensing Imagery},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Romero_2016,
	doi = {10.1109/tgrs.2015.2478379},
	url = {https://doi.org/10.1109%2Ftgrs.2015.2478379},
	year = 2016,
	month = {mar},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {54},
	number = {3},
	pages = {1349--1362},
	author = {Adriana Romero and Carlo Gatta and Gustau Camps-Valls},
	title = {Unsupervised Deep Feature Extraction for Remote Sensing Image Classification},
	journal = {IEEE Trans. Geosci. Remote Sensing} # Transactions # on # Geoscience # and # Remote # Sensing
}

@article{Safari_2021,
	doi = {10.1109/lgrs.2020.2966987},
	url = {https://doi.org/10.1109%2Flgrs.2020.2966987},
	year = 2021,
	month = {jan},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {18},
	number = {1},
	pages = {167--171},
	author = {Kazem Safari and Saurabh Prasad and Demetrio Labate},
	title = {A Multiscale Deep Learning Approach for High-Resolution Hyperspectral Image Classification},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@article{Samarinas_2020,
	abstract = {<jats:p>The agricultural sector and natural resources are heavily interdependent, comprising a coherent but complex system. The soil and water assessment tool (SWAT) is widely used in assessing these interdependencies for regional watershed management. However, long-term simulations of agricultural watersheds are considered as not realistic since they have often been performed assuming constant land use over time and are based on the coarse resolution of the existing global or national data. This work presents the first insights of the synergy among SWAT model and deep learning classification algorithms to provide annually updated and realistic model’s parameterization and simulations. The proposed hybrid modelling approach couples the physical process SWAT model with the versatility of Earth observation data-driven non-linear deep learning algorithms for land use classification (Overall Accuracy (OA) = 79.58% and Kappa = 0.79), giving a strong advantage to decision makers for efficient management planning. A validation case at an agricultural watershed located in Northern Greece is provided to demonstrate their synergistic use to estimate nitrate and sediment concentrations that load in Zazari Lake. The SWAT model has been implemented under two different simulations; one with the use of a static coarse land use map and the other with the use of the annual updated land use maps for three consecutive years (2017–2019). The results indicate that the land use changes affect the final estimations resulting to an enhanced prediction performance of 1% and 2% for sediment and nitrate, respectively, when the annual land use maps are incorporated into SWAT simulations. In this context, a hybrid approach could further contribute to addressing challenges and support a data-centric scheme for informed decision making with regard to environmental and agricultural issues on the river basin scale.</jats:p>},
	author = {Nikiforos Samarinas and Nikolaos Tziolas and George Zalidis},
	doi = {10.3390/ijgi9100576},
	journal = {IJGI} # International # Journal # of # Geo-Information
}

@article{Scott_2017,
	doi = {10.1109/lgrs.2017.2657778},
	url = {https://doi.org/10.1109%2Flgrs.2017.2657778},
	year = 2017,
	month = {apr},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {14},
	number = {4},
	pages = {549--553},
	author = {Grant J. Scott and Matthew R. England and William A. Starms and Richard A. Marcum and Curt H. Davis},
	title = {Training Deep Convolutional Neural Networks for Land{\textendash}Cover Classification of High-Resolution Imagery},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@article{Scott_2018,
	doi = {10.1109/lgrs.2018.2839092},
	url = {https://doi.org/10.1109%2Flgrs.2018.2839092},
	year = 2018,
	month = {sep},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {15},
	number = {9},
	pages = {1451--1455},
	author = {Grant J. Scott and Kyle C. Hagan and Richard A. Marcum and James Alex Hurt and Derek T. Anderson and Curt H. Davis},
	title = {Enhanced Fusion of Deep Neural Networks for Classification of Benchmark High-Resolution Image Data Sets},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@article{Seresinhe_2017,
	abstract = {<jats:p>
            Beautiful outdoor locations are protected by governments and have recently been shown to be associated with better health. But what makes an outdoor space beautiful? Does a beautiful outdoor location differ from an outdoor location that is simply natural? Here, we explore whether ratings of over 200 000 images of Great Britain from the online game
            <jats:italic>Scenic-Or-Not</jats:italic>
            , combined with hundreds of image features extracted using the Places Convolutional Neural Network, might help us understand what beautiful outdoor spaces are composed of. We discover that, as well as natural features such as ‘Coast’, ‘Mountain’ and ‘Canal Natural’, man-made structures such as ‘Tower’, ‘Castle’ and ‘Viaduct’ lead to places being considered more scenic. Importantly, while scenes containing ‘Trees’ tend to rate highly, places containing more bland natural green features such as ‘Grass’ and ‘Athletic Fields’ are considered less scenic. We also find that a neural network can be trained to automatically identify scenic places, and that this network highlights both natural and built locations. Our findings demonstrate how online data combined with neural networks can provide a deeper understanding of what environments we might find beautiful and offer quantitative insights for policymakers charged with design and protection of our built and natural environments.
          </jats:p>},
	author = {Chanuki Illushka Seresinhe and Tobias Preis and Helen Susannah Moat},
	doi = {10.1098/rsos.170170},
	journal = {R. Soc. open sci.},
	month = {jul},
	number = {7},
	pages = {170170},
	publisher = {The Royal Society},
	title = {Using deep learning to quantify the beauty of outdoor places},
	url = {https://doi.org/10.1098%2Frsos.170170},
	volume = {4},
	year = {2017}
}

@article{Shen_2020,
	doi = {10.1016/j.rse.2020.111692},
	url = {https://doi.org/10.1016%2Fj.rse.2020.111692},
	year = 2020,
	month = {apr},
	publisher = {Elsevier {BV}},
	volume = {240},
	pages = {111692},
	author = {Huanfeng Shen and Yun Jiang and Tongwen Li and Qing Cheng and Chao Zeng and Liangpei Zhang},
	title = {Deep learning-based air temperature mapping by fusing remote sensing, station, simulation and socioeconomic data},
	journal = {Remote Sensing of Environment}
}

@inproceedings{Shendryk_2018,
	doi = {10.1109/igarss.2018.8517499},
	url = {https://doi.org/10.1109%2Figarss.2018.8517499},
	year = 2018,
	month = {jul},
	publisher = {{IEEE}},
	author = {Iurii Shendryk and Yannik Rist and Rob Lucas and Peter Thorburn and Catherine Ticehurst},
	title = {Deep Learning - a New Approach for Multi-Label Scene Classification in Planetscope and Sentinel-2 Imagery},
	booktitle = {{IGARSS} 2018 - 2018 {IEEE} International Geoscience and Remote Sensing Symposium}
}

@article{Shendryk_2019,
	doi = {10.1016/j.isprsjprs.2019.08.018},
	url = {https://doi.org/10.1016%2Fj.isprsjprs.2019.08.018},
	year = 2019,
	month = {nov},
	publisher = {Elsevier {BV}},
	volume = {157},
	pages = {124--136},
	author = {Yuri Shendryk and Yannik Rist and Catherine Ticehurst and Peter Thorburn},
	title = {Deep learning for multi-modal classification of cloud, shadow and land cover scenes in {PlanetScope} and Sentinel-2 imagery},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing} # Journal # of # Photogrammetry # and # Remote # Sensing
}

@article{Song_2019,
	abstract = {<jats:p>The efficient and accurate application of deep learning in the remote sensing field largely depends on the pre-processing technology of remote sensing images. Particularly, image fusion is the essential way to achieve the complementarity of the panchromatic band and multispectral bands in high spatial resolution remote sensing images. In this paper, we not only pay attention to the visual effect of fused images, but also focus on the subsequent application effectiveness of information extraction and feature recognition based on fused images. Based on the WorldView-3 images of Tongzhou District of Beijing, we apply the fusion results to conduct the experiments of object recognition of typical urban features based on deep learning. Furthermore, we perform a quantitative analysis for the existing pixel-based mainstream fusion methods of IHS (Intensity-Hue Saturation), PCS (Principal Component Substitution), GS (Gram Schmidt), ELS (Ehlers), HPF (High-Pass Filtering), and HCS (Hyper spherical Color Space) from the perspectives of spectrum, geometric features, and recognition accuracy. The results show that there are apparent differences in visual effect and quantitative index among different fusion methods, and the PCS fusion method has the most satisfying comprehensive effectiveness in the object recognition of land cover (features) based on deep learning.</jats:p>},
	author = {Shiran Song and Jianhua Liu and Heng Pu and Yuan Liu and Jingyan Luo},
	doi = {10.3390/rs11121435},
	journal = {Remote Sensing},
	month = {jun},
	number = {12},
	pages = {1435},
	publisher = {{MDPI} {AG}},
	title = {The Comparison of Fusion Methods for {HSRRSI} Considering the Effectiveness of Land Cover (Features) Object Recognition Based on Deep Learning},
	url = {https://doi.org/10.3390%2Frs11121435},
	volume = {11},
	year = {2019}
}

@article{Sothe_2019,
	doi = {10.1080/01431161.2019.1681600},
	url = {https://doi.org/10.1080%2F01431161.2019.1681600},
	year = 2019,
	month = {oct},
	publisher = {Informa {UK} Limited},
	volume = {41},
	number = {5},
	pages = {1943--1969},
	author = {C. Sothe and C. M. De Almeida and M. B. Schimalski and V. Liesenberg and L. E. C. La Rosa and J. D. B. Castro and R. Q. Feitosa},
	title = {A comparison of machine and deep-learning algorithms applied to multisource data for a subtropical forest area classification},
	journal = {International Journal of Remote Sensing}
}

@article{Srivastava_2018,
	doi = {10.1080/13658816.2018.1542698},
	url = {https://doi.org/10.1080%2F13658816.2018.1542698},
	year = 2018,
	month = {nov},
	publisher = {Informa {UK} Limited},
	volume = {34},
	number = {6},
	pages = {1117--1136},
	author = {Shivangi Srivastava and John E. Vargas Mu{\~{n}}oz and Sylvain Lobry and Devis Tuia},
	title = {Fine-grained landuse characterization using ground-based pictures: a deep learning solution based on globally available data},
	journal = {International Journal of Geographical Information Science}
}

@article{Srivastava_2019,
	doi = {10.1016/j.rse.2019.04.014},
	url = {https://doi.org/10.1016%2Fj.rse.2019.04.014},
	year = 2019,
	month = {jul},
	publisher = {Elsevier {BV}},
	volume = {228},
	pages = {129--143},
	author = {Shivangi Srivastava and John E. Vargas-Mu{\~{n}}oz and Devis Tuia},
	title = {Understanding urban landuse from the above and ground perspectives: A deep learning, multimodal solution},
	journal = {Remote Sensing of Environment}
}

@article{Stivaktakis_2019,
	doi = {10.1109/lgrs.2019.2893306},
	url = {https://doi.org/10.1109%2Flgrs.2019.2893306},
	year = 2019,
	month = {jul},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {16},
	number = {7},
	pages = {1031--1035},
	author = {Radamanthys Stivaktakis and Grigorios Tsagkatakis and Panagiotis Tsakalides},
	title = {Deep Learning for Multilabel Land Cover Scene Categorization Using Data Augmentation},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@inproceedings{Storie_2018,
	doi = {10.1109/igarss.2018.8518619},
	url = {https://doi.org/10.1109%2Figarss.2018.8518619},
	year = 2018,
	month = {jul},
	publisher = {{IEEE}},
	author = {Christopher D. Storie and Christopher J Henry},
	title = {Deep Learning Neural Networks for Land Use Land Cover Mapping},
	booktitle = {{IGARSS} 2018 - 2018 {IEEE} International Geoscience and Remote Sensing Symposium}
}

@article{Sun_2020,
	doi = {10.1109/jstars.2020.2983331},
	url = {https://doi.org/10.1109%2Fjstars.2020.2983331},
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {13},
	pages = {1400--1415},
	author = {Jie Sun and Liping Di and Ziheng Sun and Jieyong Wang and Yingdan Wu},
	title = {Estimation of {GDP} Using Deep Learning With {NPP}-{VIIRS} Imagery and Land Cover Data at the County Level in {CONUS}},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Teng_2020,
	doi = {10.1109/lgrs.2019.2931305},
	url = {https://doi.org/10.1109%2Flgrs.2019.2931305},
	year = 2020,
	month = {may},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {17},
	number = {5},
	pages = {789--793},
	author = {Wenxiu Teng and Ni Wang and Huihui Shi and Yuchan Liu and Jing Wang},
	title = {Classifier-Constrained Deep Adversarial Domain Adaptation for Cross-Domain Semisupervised Classification in Remote Sensing Images},
	journal = {IEEE Geosci. Remote Sensing Lett.} # Geoscience # and # Remote # Sensing # Letters
}

@article{Tombe_2020,
	doi = {10.1109/jstars.2020.3044264},
	url = {https://doi.org/10.1109%2Fjstars.2020.3044264},
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	pages = {1--1},
	author = {Ronald Tombe and Serestina Viriri},
	title = {Adaptive Deep Co-occurrence Feature Learning based on Classifier-Fusion for Remote Sensing Scene Classification},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing} # Journal # of # Selected # Topics # in # Applied # Earth # Observations # and # Remote # Sensing
}

@article{Tong_2020,
	doi = {10.1016/j.rse.2019.111322},
	url = {https://doi.org/10.1016%2Fj.rse.2019.111322},
	year = 2020,
	month = {feb},
	publisher = {Elsevier {BV}},
	volume = {237},
	pages = {111322},
	author = {Xin-Yi Tong and Gui-Song Xia and Qikai Lu and Huanfeng Shen and Shengyang Li and Shucheng You and Liangpei Zhang},
	title = {Land-cover classification with high-resolution remote sensing images using transferable deep models},
	journal = {Remote Sensing of Environment}
}

@article{Tracewski_2017,
	doi = {10.1080/10095020.2017.1373955},
	url = {https://doi.org/10.1080%2F10095020.2017.1373955},
	year = 2017,
	month = {jul},
	publisher = {Informa {UK} Limited},
	volume = {20},
	number = {3},
	pages = {252--268},
	author = {Lukasz Tracewski and Lucy Bastin and Cidalia C. Fonte},
	title = {Repurposing a deep learning network to filter and classify volunteered photographs for land cover and land use characterization},
	journal = {Geo-spatial Information Science}
}

@article{Unal_2020,
	doi = {10.1109/access.2020.3000175},
	url = {https://doi.org/10.1109%2Faccess.2020.3000175},
	year = 2020,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {8},
	pages = {105587--105609},
	author = {Zeynep Unal},
	title = {Smart Farming Becomes Even Smarter With Deep Learning{\textemdash}A Bibliographical Analysis},
	journal = {IEEE Access} # Access
}

@article{Unnikrishnan_2019,
	doi = {10.1007/s11042-019-7179-2},
	url = {https://doi.org/10.1007%2Fs11042-019-7179-2},
	year = 2019,
	month = {jan},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {78},
	number = {13},
	pages = {18379--18394},
	author = {Anju Unnikrishnan and V. Sowmya and K. P. Soman},
	title = {Deep learning architectures for land cover classification using red and near-infrared satellite images},
	journal = {Multimed Tools Appl}
}

@article{Vali_2020,
	abstract = {<jats:p>Lately, with deep learning outpacing the other machine learning techniques in classifying images, we have witnessed a growing interest of the remote sensing community in employing these techniques for the land use and land cover classification based on multispectral and hyperspectral images; the number of related publications almost doubling each year since 2015 is an attest to that. The advances in remote sensing technologies, hence the fast-growing volume of timely data available at the global scale, offer new opportunities for a variety of applications. Deep learning being significantly successful in dealing with Big Data, seems to be a great candidate for exploiting the potentials of such complex massive data. However, there are some challenges related to the ground-truth, resolution, and the nature of data that strongly impact the performance of classification. In this paper, we review the use of deep learning in land use and land cover classification based on multispectral and hyperspectral images and we introduce the available data sources and datasets used by literature studies; we provide the readers with a framework to interpret the-state-of-the-art of deep learning in this context and offer a platform to approach methodologies, data, and challenges of the field.</jats:p>},
	author = {Ava Vali and Sara Comai and Matteo Matteucci},
	doi = {10.3390/rs12152495},
	journal = {Remote Sensing},
	month = {aug},
	number = {15},
	pages = {2495},
	publisher = {{MDPI} {AG}},
	title = {Deep Learning for Land Use and Land Cover Classification Based on Hyperspectral and Multispectral Earth Observation Data: A Review},
	url = {https://doi.org/10.3390%2Frs12152495},
	volume = {12},
	year = {2020}
}

@article{Wang_2019,
	abstract = {<jats:p>Land cover classification data have a very important practical application value, and long time series land cover classification datasets are of great significance studying environmental changes, urban changes, land resource surveys, hydrology and ecology. At present, the starting point of continuous land cover classification products for many years is mostly after the year 2000, and there is a lack of long-term continuously annual land cover classification products before 2000. In this study, a long time series classification data extraction model is established using a bidirectional long-term and short-term memory network (Bi-LSTM). In the model, quantitative remote sensing products combined with DEM, nighttime lighting data, and latitude and longitude elevation data were used. We applied this model in China and obtained China’s 1982–2017 0.05° land cover classification product. The accuracy assessment results of the test data show that the overall accuracy is 84.2% and that the accuracies of wetland, water, glacier, tundra, city and bare soil reach 92.1%, 92.0%, 94.3%, 94.6% and 92.4%, respectively. For the first time, this study used a variety of long time series data, especially quantitative remote sensing products, for the classification of features. At the same time, it also acquired long time series land cover classification products, including those from the year 2000. This study provides new ideas for the establishment of higher-resolution long time series land cover classification products.</jats:p>},
	author = {Haoyu Wang and Xiang Zhao and Xin Zhang and Donghai Wu and Xiaozheng Du},
	doi = {10.3390/rs11141639},
	journal = {Remote Sensing},
	month = {jul},
	number = {14},
	pages = {1639},
	publisher = {{MDPI} {AG}},
	title = {Long Time Series Land Cover Classification in China from 1982 to 2015 Based on Bi-{LSTM} Deep Learning},
	url = {https://doi.org/10.3390%2Frs11141639},
	volume = {11},
	year = {2019}
}

@article{Wang_2020,
	abstract = {<jats:p>Accurate automated segmentation of remote sensing data could benefit applications from land cover mapping and agricultural monitoring to urban development surveyal and disaster damage assessment. While convolutional neural networks (CNNs) achieve state-of-the-art accuracy when segmenting natural images with huge labeled datasets, their successful translation to remote sensing tasks has been limited by low quantities of ground truth labels, especially fully segmented ones, in the remote sensing domain. In this work, we perform cropland segmentation using two types of labels commonly found in remote sensing datasets that can be considered sources of “weak supervision”: (1) labels comprised of single geotagged points and (2) image-level labels. We demonstrate that (1) a U-Net trained on a single labeled pixel per image and (2) a U-Net image classifier transferred to segmentation can outperform pixel-level algorithms such as logistic regression, support vector machine, and random forest. While the high performance of neural networks is well-established for large datasets, our experiments indicate that U-Nets trained on weak labels outperform baseline methods with as few as 100 labels. Neural networks, therefore, can combine superior classification performance with efficient label usage, and allow pixel-level labels to be obtained from image labels.</jats:p>},
	author = {Sherrie Wang and William Chen and Sang Michael Xie and George Azzari and David B. Lobell},
	doi = {10.3390/rs12020207},
	journal = {Remote Sensing},
	month = {jan},
	number = {2},
	pages = {207},
	publisher = {{MDPI} {AG}},
	title = {Weakly Supervised Deep Learning for Segmentation of Remote Sensing Imagery},
	url = {https://doi.org/10.3390%2Frs12020207},
	volume = {12},
	year = {2020}
}

@article{Xing_2018,
	doi = {10.1016/j.isprsjprs.2018.04.025},
	url = {https://doi.org/10.1016%2Fj.isprsjprs.2018.04.025},
	year = 2018,
	month = {jul},
	publisher = {Elsevier {BV}},
	volume = {141},
	pages = {237--251},
	author = {Hanfa Xing and Yuan Meng and Zixuan Wang and Kaixuan Fan and Dongyang Hou},
	title = {Exploring geo-tagged photos for land cover validation with deep learning},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing} # Journal # of # Photogrammetry # and # Remote # Sensing
}

@article{Xing_2020,
	doi = {10.1016/j.cageo.2020.104430},
	url = {https://doi.org/10.1016%2Fj.cageo.2020.104430},
	year = 2020,
	month = {apr},
	publisher = {Elsevier {BV}},
	volume = {137},
	pages = {104430},
	author = {Weiran Xing and Yuehui Qian and Xuefeng Guan and Tingting Yang and Huayi Wu},
	title = {A novel cellular automata model integrated with deep learning for dynamic spatio-temporal land use change simulation},
	journal = {Computers & Geosciences} # Geosciences
}

@article{Xu_2017,
	doi = {10.1016/j.envsoft.2017.02.004},
	url = {https://doi.org/10.1016%2Fj.envsoft.2017.02.004},
	year = 2017,
	month = {may},
	publisher = {Elsevier {BV}},
	volume = {91},
	pages = {127--134},
	author = {Guang Xu and Xuan Zhu and Dongjie Fu and Jinwei Dong and Xiangming Xiao},
	title = {Automatic land cover classification of geo-tagged field photos by deep learning},
	journal = {Environmental Modelling & Software} # Software
}

@article{Xu_2018,
	doi = {10.3390/rs10010144},
	url = {https://doi.org/10.3390%2Frs10010144},
	year = 2018,
	month = {jan},
	publisher = {{MDPI} {AG}},
	volume = {10},
	number = {1},
	pages = {144},
	author = {Yongyang Xu and Liang Wu and Zhong Xie and Zhanlong Chen},
	title = {Building Extraction in Very High Resolution Remote Sensing Imagery Using Deep Learning and Guided Filters},
	journal = {Remote Sensing}
}

@article{Yang_2002,
	doi = {10.1080/01431160110075802},
	url = {https://doi.org/10.1080%2F01431160110075802},
	year = 2002,
	month = {jan},
	publisher = {Informa {UK} Limited},
	volume = {23},
	number = {9},
	pages = {1775--1798},
	author = {X. Yang and C. P. Lo},
	title = {Using a time series of satellite imagery to detect land use and land cover changes in the Atlanta, Georgia metropolitan area},
	journal = {International Journal of Remote Sensing}
}

@article{Ye_2019,
	doi = {10.1016/j.envsoft.2019.07.013},
	url = {https://doi.org/10.1016%2Fj.envsoft.2019.07.013},
	year = 2019,
	month = {sep},
	publisher = {Elsevier {BV}},
	volume = {119},
	pages = {407--417},
	author = {Long Ye and Lei Gao and Raymundo Marcos-Martinez and Dirk Mallants and Brett A. Bryan},
	title = {Projecting Australia{\textquotesingle}s forest cover dynamics and exploring influential factors using deep learning},
	journal = {Environmental Modelling & Software} # Software
}

@article{Yu_2017,
	doi = {10.1080/15481603.2017.1323377},
	url = {https://doi.org/10.1080%2F15481603.2017.1323377},
	year = 2017,
	month = {may},
	publisher = {Informa {UK} Limited},
	volume = {54},
	number = {5},
	pages = {741--758},
	author = {Xingrui Yu and Xiaomin Wu and Chunbo Luo and Peng Ren},
	title = {Deep learning in remote sensing scene classification: a data augmentation enhanced convolutional neural network framework},
	journal = {GIScience & Remote Sensing} # {\&} # Remote # Sensing
}

@article{Yuan_2020,
	doi = {10.1016/j.rse.2020.111716},
	url = {https://doi.org/10.1016%2Fj.rse.2020.111716},
	year = 2020,
	month = {may},
	publisher = {Elsevier {BV}},
	volume = {241},
	pages = {111716},
	author = {Qiangqiang Yuan and Huanfeng Shen and Tongwen Li and Zhiwei Li and Shuwen Li and Yun Jiang and Hongzhang Xu and Weiwei Tan and Qianqian Yang and Jiwen Wang and Jianhao Gao and Liangpei Zhang},
	title = {Deep learning in environmental remote sensing: Achievements and challenges},
	journal = {Remote Sensing of Environment}
}

@article{Zeng_2019,
	abstract = {<jats:p>Airports have a profound impact on our lives, and uncovering their distribution around the world has great significance for research and development. However, existing airport databases are incomplete and have a high cost of updating. Thus, a fast and automatic worldwide airport detection method can be of significance for global airport detection at regular intervals. However, previous airport detection studies are usually based on single remote sensing (RS) imagery, which seems an overwhelming burden for worldwide airport detection with traversal searching. Thus, we propose a hierarchical airport detection method consisting of broad-scale extraction of worldwide candidate airport regions based on spatial analysis of released RS products, including impervious surfaces from FROM-GLC10 (fine resolution observation and monitoring of global land cover 10) product, building distribution from OSMs (open street maps) and digital surface model from AW3D30 (ALOS World 3D—30 m). Moreover, narrow-scale aircraft detection was initially conducted by the Faster R-CNN (regional-convolutional neural networks) deep learning method. To avoid overestimation of background regions by Faster R-CNN, a second CNN classifier is used to refine the class labeling with negative samples. Specifically, our research focuses on target airports with at least 2 km length in three experimental regions. Results show that spatial analysis reduced the possible regions to 0.56% of the total area of 75,691 km2. The initial aircraft detection by Faster R-CNN had a mean user’s accuracy of 88.90% and ensured that all the aircrafts could be detected. Then, by introducing the CNN reclassifier, the user’s accuracy of aircraft detection was significantly increased to 94.21%. Finally, through an experienced threshold of aircraft number, 19 of the total 20 airports were detected correctly. Our results reveal the overall workflow is reliable for automatic and rapid airport detection around the world with the help of released RS products. This research promotes the application and progression of deep learning.</jats:p>},
	author = {Fanxuan Zeng and Liang Cheng and Ning Li and Nan Xia and Lei Ma and Xiao Zhou and Manchun Li},
	doi = {10.3390/rs11192204},
	journal = {Remote Sensing},
	month = {sep},
	number = {19},
	pages = {2204},
	publisher = {{MDPI} {AG}},
	title = {A Hierarchical Airport Detection Method Using Spatial Analysis and Deep Learning},
	url = {https://doi.org/10.3390%2Frs11192204},
	volume = {11},
	year = {2019}
}

@article{Zhang_2016,
	doi = {10.1109/mgrs.2016.2540798},
	url = {https://doi.org/10.1109%2Fmgrs.2016.2540798},
	year = 2016,
	month = {jun},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {4},
	number = {2},
	pages = {22--40},
	author = {Liangpei Zhang and Lefei Zhang and Bo Du},
	title = {Deep Learning for Remote Sensing Data: A Technical Tutorial on the State of the Art},
	journal = {IEEE Geosci. Remote Sens. Mag.} # Geoscience # and # Remote # Sensing # Magazine
}

@article{Zhang_2018,
	abstract = {<jats:p>Urban land cover and land use mapping plays an important role in urban planning and management. In this paper, novel multi-scale deep learning models, namely ASPP-Unet and ResASPP-Unet are proposed for urban land cover classification based on very high resolution (VHR) satellite imagery. The proposed ASPP-Unet model consists of a contracting path which extracts the high-level features, and an expansive path, which up-samples the features to create a high-resolution output. The atrous spatial pyramid pooling (ASPP) technique is utilized in the bottom layer in order to incorporate multi-scale deep features into a discriminative feature. The ResASPP-Unet model further improves the architecture by replacing each layer with residual unit. The models were trained and tested based on WorldView-2 (WV2) and WorldView-3 (WV3) imageries over the city of Beijing. Model parameters including layer depth and the number of initial feature maps (IFMs) as well as the input image bands were evaluated in terms of their impact on the model performances. It is shown that the ResASPP-Unet model with 11 layers and 64 IFMs based on 8-band WV2 imagery produced the highest classification accuracy (87.1% for WV2 imagery and 84.0% for WV3 imagery). The ASPP-Unet model with the same parameter setting produced slightly lower accuracy, with overall accuracy of 85.2% for WV2 imagery and 83.2% for WV3 imagery. Overall, the proposed models outperformed the state-of-the-art models, e.g., U-Net, convolutional neural network (CNN) and Support Vector Machine (SVM) model over both WV2 and WV3 images, and yielded robust and efficient urban land cover classification results.</jats:p>},
	author = {Pengbin Zhang and Yinghai Ke and Zhenxin Zhang and Mingli Wang and Peng Li and Shuangyue Zhang},
	doi = {10.3390/s18113717},
	journal = {Sensors},
	month = {nov},
	number = {11},
	pages = {3717},
	publisher = {{MDPI} {AG}},
	title = {Urban Land Use and Land Cover Classification Using Novel Deep Learning Models Based on High Spatial Resolution Satellite Imagery},
	url = {https://doi.org/10.3390%2Fs18113717},
	volume = {18},
	year = {2018}
}

@article{Zhang_2019,
	doi = {10.1016/j.rse.2018.11.014},
	url = {https://doi.org/10.1016%2Fj.rse.2018.11.014},
	year = 2019,
	month = {feb},
	publisher = {Elsevier {BV}},
	volume = {221},
	pages = {173--187},
	author = {Ce Zhang and Isabel Sargent and Xin Pan and Huapeng Li and Andy Gardiner and Jonathon Hare and Peter M. Atkinson},
	title = {Joint Deep Learning for land cover and land use classification},
	journal = {Remote Sensing of Environment}
}

@article{Zhang_2020,
	abstract = {<jats:p>Land cover information plays an important role in mapping ecological and environmental changes in Earth’s diverse landscapes for ecosystem monitoring. Remote sensing data have been widely used for the study of land cover, enabling efficient mapping of changes of the Earth surface from Space. Although the availability of high-resolution remote sensing imagery increases significantly every year, traditional land cover analysis approaches based on pixel and object levels are not optimal. Recent advancement in deep learning has achieved remarkable success on image recognition field and has shown potential in high spatial resolution remote sensing applications, including classification and object detection. In this paper, a comprehensive review on land cover classification and object detection approaches using high resolution imagery is provided. Through two case studies, we demonstrated the applications of the state-of-the-art deep learning models to high spatial resolution remote sensing data for land cover classification and object detection and evaluated their performances against traditional approaches. For a land cover classification task, the deep-learning-based methods provide an end-to-end solution by using both spatial and spectral information. They have shown better performance than the traditional pixel-based method, especially for the categories of different vegetation. For an objective detection task, the deep-learning-based object detection method achieved more than 98% accuracy in a large area; its high accuracy and efficiency could relieve the burden of the traditional, labour-intensive method. However, considering the diversity of remote sensing data, more training datasets are required in order to improve the generalisation and the robustness of deep learning-based models.</jats:p>},
	author = {Xin Zhang and Liangxiu Han and Lianghao Han and Liang Zhu},
	doi = {10.3390/rs12030417},
	journal = {Remote Sensing},
	month = {jan},
	number = {3},
	pages = {417},
	publisher = {{MDPI} {AG}},
	title = {How Well Do Deep Learning-Based Methods for Land Cover Classification and Object Detection Perform on High Resolution Remote Sensing Imagery?},
	url = {https://doi.org/10.3390%2Frs12030417},
	volume = {12},
	year = {2020}
}

@article{Zhao_2020,
	abstract = {<jats:p>Land cover is one of key indicators for modeling ecological, environmental, and climatic processes, which changes frequently due to natural factors and anthropogenic activities. The changes demand various samples for updating land cover maps, although in reality the number of samples is always insufficient. Sample augment methods can fill this gap, but these methods still face difficulties, especially for high-resolution remote sensing data. The difficulties include the following: (1) excessive human involvement, which is mostly caused by human interpretation, even by active learning-based methods; (2) large variations of segmented land cover objects, which affects the generalization to unseen areas especially for proposed methods that are validated in small study areas. To solve these problems, we proposed a sample augment method incorporating the deep neural networks using a Gaofen-2 image. To avoid error accumulation, the neural network-based sample augment (NNSA) framework employs non-iterative procedure, and augments from 184 image objects with labels to 75,112 samples. The overall accuracy (OA) of NNSA is 20% higher than that of label propagation (LP) in reference to expert interpreted results; the LP has an OA of 61.16%. The accuracy decreases by approximately 10% in the coastal validation area, which has different characteristics from the inland samples. We also compared the iterative and non-iterative strategies without external information added. The results of the validation area containing original samples show that non-iterative methods have a higher OA and a lower sample imbalance. The NNSA method that augments sample size with higher accuracy can benefit the update of land cover information.</jats:p>},
	author = {Chuanpeng Zhao and Yaohuan Huang},
	doi = {10.3390/land9080271},
	journal = {Land},
	month = {aug},
	number = {8},
	pages = {271},
	publisher = {{MDPI} {AG}},
	title = {A Deep Neural Networks Approach for Augmenting Samples of Land Cover Classification},
	url = {https://doi.org/10.3390%2Fland9080271},
	volume = {9},
	year = {2020}
}

@inproceedings{Zhong_2017,
	doi = {10.1109/igarss.2017.8127330},
	url = {https://doi.org/10.1109%2Figarss.2017.8127330},
	year = 2017,
	month = {jul},
	publisher = {{IEEE}},
	author = {Zilong Zhong and Jonathan Li and Lingfei Ma and Han Jiang and He Zhao},
	title = {Deep residual networks for hyperspectral image classification},
	booktitle = {2017 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})}
}

@article{Zhong_2018,
	doi = {10.1109/tgrs.2017.2755542},
	url = {https://doi.org/10.1109%2Ftgrs.2017.2755542},
	year = 2018,
	month = {feb},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {56},
	number = {2},
	pages = {847--858},
	author = {Zilong Zhong and Jonathan Li and Zhiming Luo and Michael Chapman},
	title = {Spectral{\textendash}Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework},
	journal = {IEEE Trans. Geosci. Remote Sensing} # Transactions # on # Geoscience # and # Remote # Sensing
}

@article{Zhong_2019,
	doi = {10.1016/j.rse.2018.11.032},
	url = {https://doi.org/10.1016%2Fj.rse.2018.11.032},
	year = 2019,
	month = {feb},
	publisher = {Elsevier {BV}},
	volume = {221},
	pages = {430--443},
	author = {Liheng Zhong and Lina Hu and Hang Zhou},
	title = {Deep learning based multi-temporal crop classification},
	journal = {Remote Sensing of Environment}
}

@inproceedings{Zhou_2017,
	doi = {10.1109/icsai.2017.8248497},
	url = {https://doi.org/10.1109%2Ficsai.2017.8248497},
	year = 2017,
	month = {nov},
	publisher = {{IEEE}},
	author = {Zhuang Zhou and Shengyang Li},
	title = {Peanut planting area change monitoring from remote sensing images based on deep learning},
	booktitle = {2017 4th International Conference on Systems and Informatics ({ICSAI})}
}

@article{Zhu_2014,
	doi = {10.1016/j.rse.2014.01.011},
	url = {https://doi.org/10.1016%2Fj.rse.2014.01.011},
	year = 2014,
	month = {mar},
	publisher = {Elsevier {BV}},
	volume = {144},
	pages = {152--171},
	author = {Zhe Zhu and Curtis E. Woodcock},
	title = {Continuous change detection and classification of land cover using all available Landsat data},
	journal = {Remote Sensing of Environment}
}

@article{Zhu_2017,
	doi = {10.1109/mgrs.2017.2762307},
	url = {https://doi.org/10.1109%2Fmgrs.2017.2762307},
	year = 2017,
	month = {dec},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {5},
	number = {4},
	pages = {8--36},
	author = {Xiao Xiang Zhu and Devis Tuia and Lichao Mou and Gui-Song Xia and Liangpei Zhang and Feng Xu and Friedrich Fraundorfer},
	title = {Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources},
	journal = {IEEE Geosci. Remote Sens. Mag.} # Geoscience # and # Remote # Sensing # Magazine
}

